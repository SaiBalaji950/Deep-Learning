{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c413ad47-8ea4-4b0b-ad75-8453f4ed34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pytorch Mean and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc6699b-51f9-454b-b7b9-95d596772068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.5000)\n",
      "tensor(3.0277)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([1,2,3,4,5,6,7,8,9,10],dtype=torch.float)\n",
    "mean=a.mean(dim=0)\n",
    "std=a.std(dim=0)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccb07752-f6ed-46a0-b7a5-ffe14cc12c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.5000)\n",
      "tensor(3.0277)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([1,2,3,4,5,6,7,8,9,10]).float()\n",
    "mean=a.mean(dim=0)\n",
    "std=a.std(dim=0)\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86618d74-8bf9-4a14-b110-0f0b7dca2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensors Introduction\n",
    "\n",
    "\n",
    "Tensors are the key components of Pytorch. We can say PyTorch is wholly based on the Tensors. \n",
    "In mathematics, a rectangular array of number is called metrics. In NumPy library, these metrics called ndaaray. \n",
    "In PyTorch, it is known as Tensor. A tensor is an n-dimensional data container. \n",
    "For example, In PyTorch, 1d-tensor is a vector, 2d-tensor is a metrics, 3d- tensor is a cube, and 4d-tensor is a cube vector.\n",
    "\n",
    "Torch provides tensor computation with strong GPU acceleration. \n",
    "It is essential that we get familiar with the tensor data structure to work with PyTorch. \n",
    "It will serve as a fundamental prerequisite before neural network implementation.\n",
    "\n",
    "In Deep learning, Tensor is the key part, and we can see so many discussion around Tensor. \n",
    "Even it appears in the name of Googles main machine learning library, i.e., TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50495b1-e3a8-4b4d-ac59-8ed9dc61189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "How to create Tensor?\n",
    "There are three ways by which we can create the Tensor. Each one has a different way to createTensor and use a different method. Tensors are created as\n",
    "\n",
    "Create Tensor from an array\n",
    "Create Tensor with all ones and random number\n",
    "Create Tensor from numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f17514-46da-4d23-904a-ea54f3ae6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create Tensor from an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e21f6cac-96e7-4f59-85ed-b305baf5eee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 4],\n",
      "        [3, 5]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "array=[[2,4],[3,5]]\n",
    "a=torch.tensor(array)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f14f85e-5535-4472-8227-50e4f6b3986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create a Tensor from numpy array\n",
    "\n",
    "To create a tensor from the numpy array, we have to create a numpy array. \n",
    "Once your numpy array is created, we have to pass it in from_numpy() as an argument. This method converts the numpy array to tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d5dfcbe-d1e0-4195-9ab4-255812d26742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "numpy_arr=np.ones((2,2))\n",
    "pytorch=torch.from_numpy(numpy_arr)\n",
    "a=pytorch.numpy()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adbd2c9e-86f4-42a8-9c51-1c09c96a67e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "numpy_arr=np.ones((5,5))\n",
    "pytorch=torch.from_numpy(numpy_arr)\n",
    "a=pytorch.numpy()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44c2f02f-da96-4b24-9f32-9b44a9449fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "numpy_arr=np.ones((10,5))\n",
    "pytorch=torch.from_numpy(numpy_arr)\n",
    "a=pytorch.numpy()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cc1acb4-3768-4462-9e5d-9b1cf0d2709e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "numpy_arr=np.ones((5,10))\n",
    "pytorch=torch.from_numpy(numpy_arr)\n",
    "a=pytorch.numpy()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3338037a-eebf-4fa5-a144-3bc78a17d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "One Dimensional Tensors\n",
    "As we know, PyTorch has been embraced by Deep learning world for the ability to conveniently define neural network. \n",
    "Neural network is fundamentally structured to sensors, and PyTorch is also built around sensors. There tends to be a significant boost in performance. \n",
    "Vaguely a tensor is a generalization of matrices.\n",
    "\n",
    "One Dimensional Tensors\n",
    "1D-Tensor is similar to 1D- matrix. In one dimensional Tensor have only one row and one column which is known as vector. \n",
    "There is a zero-dimensional tensor also which is known as a scalar.\n",
    "\n",
    "Now we will discuss operations which are performed on tensors.\n",
    "\n",
    "We can use Google Colab also to write the code of Tensor. Accessing Google Colab is very simple. \n",
    "For Google Colab, There is no setup required. It runs entirely on the cloud.\n",
    "\n",
    "One Dimensional Tensors\n",
    "Google Colab is similar to Jupyter Notebook. Many packages come pre-install for us when using Google Colab. \n",
    "Unfortunately, the torch is not one of them, so we have first to install torch using !pip3 install torch command.\n",
    "\n",
    "Now, we will perform the operation on one-dimensional Tensor.\n",
    "\n",
    "Creating one-dimensional Tensor\n",
    "For creating a one-dimensional Tensor, we use the tensor property of torch library. To create a tensor, we use the torch.tensor() method.\n",
    "\n",
    "Syntax of creating one dimensional tensor is as follows:\n",
    "\n",
    "n= torch.tensor([Tensor elements])  \n",
    "Here, n is a variable of tensor type and tensor elements can be any integer or floating point number following with (,)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "649e8aab-b342-4a24-bc09-bf3266af9b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([1,2,3,4,5])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf2ce03-41d5-4646-90a1-56b222f97a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Checking data type of elements in Tensor\n",
    "We can check the data type of the element which contains in Tensor. We use dtype() of Tensor to find the data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42aadc9c-f446-481e-bb56-499149f24367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([1,2,3])\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b193754-b344-4730-afe1-cecf4af015d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([1.0,9.0,11.0])\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c01ed8-4d75-4761-9a3c-0d02f6f4313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accessing of Tensors elements\n",
    "\n",
    "We can access the elements of Tensor with the help of the index of that element. \n",
    "If we want to print all the elements of Tensor, then we can print the tensor variable. \n",
    "Like the one-dimensional metrics index, Tensor index also starts from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56827432-9a2d-4218-9df2-ef281f08061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([1.0,2.0,3.0])\n",
    "print(a[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c0134c0-4f9e-4b07-802b-9a823e7083c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([1.0,2.0,3.0,4.0,5.0])\n",
    "print(a[4])\n",
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f8953f-94d0-4fba-b331-690695f705fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accessing of Tensor's elements with the specified range\n",
    "\n",
    "It is quite simple to access elements of specified range by passing the starting index or ending index of elements separated with a colon (:). \n",
    "It will skip starting index element and print elements till ending index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dabe439-ae30-4c93-abd2-0422c86c24e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "tensor([1, 2, 3])\n",
      "tensor([1, 2])\n",
      "tensor([1])\n",
      "tensor(1)\n",
      "tensor(1)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([1,2,3,4])\n",
    "print(a[0:4])\n",
    "print(a[0:3])\n",
    "print(a[0:2])\n",
    "print(a[0:1])\n",
    "print(a[0])\n",
    "print(a[0])\n",
    "print(a[1])\n",
    "print(a[2])\n",
    "print(a[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efae429-b81c-43a0-b7c7-de33bce9794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Creating of Floating Point Tensor using Integer elements\n",
    "We can create a floating point Tensor using integer element. In this, we use FloatTensor property of torch is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a234147c-5a53-4824-b9a3-53af0d73f9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "a=th.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f528f487-e919-4fdc-8597-858655d1f261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "a=th.FloatTensor([1,2,3,4,5,6,7,8,9,10])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d605a-7789-4d7e-94ea-d36f7a53ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Finding size of the Tensor\n",
    "Just like one dimensional metrics, we can find the size of Tensor also. We use size() method of Tensor to get the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13500d65-4df9-47a7-9140-15749561d46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d09a11-472d-401a-858b-45880aa59c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Change view of Tensor\n",
    "\n",
    "Tensor has the property by which we can change the view of the Tensor.\n",
    "Changing view means if a tensor is one dimensional (one row and one column) and \n",
    "we want to change its view by six rows and one column.Changes can be done with the help of view() of Tensor. \n",
    "It is similar to the reshape () of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ccf31e1-e7b5-4adf-a010-0021a33dc3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([1,2,3,4,5,6])\n",
    "print(a)\n",
    "a.view(6,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "211da8d1-a184-4400-987e-58e1f076e68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.],\n",
       "        [ 2.],\n",
       "        [ 3.],\n",
       "        [ 4.],\n",
       "        [ 5.],\n",
       "        [ 6.],\n",
       "        [ 7.],\n",
       "        [ 8.],\n",
       "        [ 9.],\n",
       "        [10.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.FloatTensor([1,2,3,4,5,6,7,8,9,10])\n",
    "print(a)\n",
    "a.view(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb328d4-6703-42fc-99ee-5ba008da860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor using numpy array\n",
    "\n",
    "We can also create Tensor using numpy array. We have to convert the numpy array into Tensor with the help of from_numpy () of the torch. \n",
    "For this, we first have to initialize numpy and then create a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "987d244c-641e-4a72-8fce-0101d0ad9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6], dtype=torch.int32)\n",
      "torch.IntTensor\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "a=np.array([1,2,3,4,5,6])\n",
    "b=torch.from_numpy(a)\n",
    "print(b)\n",
    "print(b.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35183708-7377-4063-b7af-7d8b126d2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dotproduct and linspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2ed1491-aa75-4372-bbdf-add3d93de071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32)\n",
      "tensor([2.0000, 5.5000, 9.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([1,2,3])\n",
    "b=torch.tensor([4,5,6])\n",
    "c=torch.dot(a,b)\n",
    "print(c)\n",
    "d=torch.linspace(2,9,steps=3)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb0255b1-b704-4825-b7ff-c21c5835c419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32)\n",
      "tensor([2.0000, 2.7778, 3.5556, 4.3333, 5.1111, 5.8889, 6.6667, 7.4444, 8.2222,\n",
      "        9.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([1,2,3])\n",
    "b=torch.tensor([4,5,6])\n",
    "c=torch.dot(a,b)\n",
    "print(c)\n",
    "d=torch.linspace(2,9,steps=10)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c461d4e8-1441-4078-b698-7a5667fdb3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32)\n",
      "tensor([2.0000, 2.0707, 2.1414, 2.2121, 2.2828, 2.3535, 2.4242, 2.4949, 2.5657,\n",
      "        2.6364, 2.7071, 2.7778, 2.8485, 2.9192, 2.9899, 3.0606, 3.1313, 3.2020,\n",
      "        3.2727, 3.3434, 3.4141, 3.4848, 3.5556, 3.6263, 3.6970, 3.7677, 3.8384,\n",
      "        3.9091, 3.9798, 4.0505, 4.1212, 4.1919, 4.2626, 4.3333, 4.4040, 4.4747,\n",
      "        4.5455, 4.6162, 4.6869, 4.7576, 4.8283, 4.8990, 4.9697, 5.0404, 5.1111,\n",
      "        5.1818, 5.2525, 5.3232, 5.3939, 5.4646, 5.5354, 5.6061, 5.6768, 5.7475,\n",
      "        5.8182, 5.8889, 5.9596, 6.0303, 6.1010, 6.1717, 6.2424, 6.3131, 6.3838,\n",
      "        6.4545, 6.5253, 6.5960, 6.6667, 6.7374, 6.8081, 6.8788, 6.9495, 7.0202,\n",
      "        7.0909, 7.1616, 7.2323, 7.3030, 7.3737, 7.4444, 7.5152, 7.5859, 7.6566,\n",
      "        7.7273, 7.7980, 7.8687, 7.9394, 8.0101, 8.0808, 8.1515, 8.2222, 8.2929,\n",
      "        8.3636, 8.4343, 8.5051, 8.5758, 8.6465, 8.7172, 8.7879, 8.8586, 8.9293,\n",
      "        9.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([1,2,3])\n",
    "b=torch.tensor([4,5,6])\n",
    "c=torch.dot(a,b)\n",
    "print(c)\n",
    "d=torch.linspace(2,9,steps=100)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d464c-b758-46d7-900b-8bffd0989d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotting a function on the two-dimensional coordinate system\n",
    "\n",
    "The linspace function can come in use when plotting a function on two-dimensional coordinate systems. \n",
    "For the x-axis, we create a land space from 0 to 10 in an interval of 2.5, and Y will be the function of each x value. \n",
    "For example, we can find the exponential of each x value for y.\n",
    "\n",
    "Now, we are plotting x and y data using Map plot lib library, which is a visualization library for data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f0b21e7-cdf9-478e-afd7-d794ae67d17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x=torch.linspace(0,50,100)\n",
    "y=torch.exp(x)\n",
    "plt.plot(x.numpy(),y.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53ef81f8-863f-45d4-94e7-5776a85da3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x=torch.linspace(0,10,100)\n",
    "y=torch.exp(x)\n",
    "plt.plot(x.numpy(),y.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8202d-1d29-4f78-a6a0-b62ed5319acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Two Dimensional Tensor\n",
    "Two-dimensional tensor is similar to the two-dimensional metrics. A two-dimensional metrics have n number of rows and n number of columns. \n",
    "Similarly, two-dimensional tensor has n rows and n columns also.\n",
    "\n",
    "A two-dimensional tensor has the following representation\n",
    "\n",
    "Two Dimensional Tensor\n",
    "A gray scalar image is a two-dimensional matrix of pixels. \n",
    "Each pixels intensity denoted by a numeric value that ranges from 0 to 255 such that intensity value of 0 \n",
    "indicates no intensity something being completely black and 255 representing of maximum intensity something being completely white. \n",
    "We can store this two-dimensional grid of values.\n",
    "\n",
    "Two Dimensional Tensor\n",
    "Creating two-dimensional tensor\n",
    "For creating a two-dimensional tensor, you have first to create a one-dimensional tensor using arrange () method of the torch. \n",
    "This method contains two parameters of integer type. This method arranges the elements in tensor as per the given parameters. \n",
    "Once your one-dimensional tensor is created, then our next step is to change its view in two-dimensional form\n",
    "and store this view in the two-dimensional type of variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff9c897e-3e5b-41ff-a2f2-23da3fa29750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8145e7a-718e-4772-ac99-52bbe8c53c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.arange(0,9)\n",
    "print(x)\n",
    "y=x.view(3,3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5d81ecd-56cc-4d2e-9151-8d329eb7cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.arange(0,9)\n",
    "print(x)\n",
    "y=x.view(3,3)\n",
    "print(y)\n",
    "print(x.dim())\n",
    "print(y.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97719f31-7076-48c1-a6bf-adeec856f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accessing two-dimensional tensor elements\n",
    "Let see an example of two-dimensional tensor to understand how to access a particular element from two-dimensional tensor using index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1899b22-da67-4ed0-8cec-738335673c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 8])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.arange(0,9)\n",
    "print(x)\n",
    "y=x.view(3,3)\n",
    "print(y)\n",
    "y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f068c999-8dff-4b8c-8201-f856e9689914",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensors Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "783a8518-77c2-462a-ad83-8d570fe4919e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 4, 6],\n",
      "        [8, 1, 3],\n",
      "        [5, 7, 9]])\n",
      "tensor([[2, 4, 6],\n",
      "        [8, 1, 3],\n",
      "        [5, 7, 9]])\n",
      "tensor([[ 66,  54,  78],\n",
      "        [ 39,  54,  78],\n",
      "        [111,  90, 132]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.tensor([2,4,6,8,1,3,5,7,9])\n",
    "a=a.view(3,3)\n",
    "b=torch.tensor([2,4,6,8,1,3,5,7,9])\n",
    "b=b.view(3,3)\n",
    "print(a)\n",
    "print(b)\n",
    "c=torch.matmul(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095c585-651a-41ae-8a6a-842fa4d03f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Three Dimensional Tensor\n",
    "Three-dimensional tensor is made with the help of view () method. A three-dimensional tensor has the following structure\n",
    "\n",
    "Two Dimensional Tensor\n",
    "Accessing element from 3D- Tensor\n",
    "Accessing elements from the 3D-tensor is quite easy. It will be done using the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37d2e1fb-c0fe-4937-a307-020a5dd04c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])\n",
      "tensor(10)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.arange(18)\n",
    "print(x)\n",
    "y=x.view(3,2,3)\n",
    "print(y[1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37632c-2b8e-4a5d-a8cc-5394ab9f085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Slicing of three-dimensional tensor\n",
    "Segment slices are very similar to how we would slice a one-dimensional tensor. Slicing a \n",
    "tensor means to slice the elements of a tensor into a new tensor, or we can say slicing is a process of creating a new tensor by dividing a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42192d8f-08d1-4024-bd7e-5e26379cde9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]],\n",
      "\n",
      "        [[12, 13, 14],\n",
      "         [15, 16, 17]]])\n",
      "tensor([[ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "x=torch.arange(18)\n",
    "print(x)\n",
    "y=x.view(3,2,3)\n",
    "print(y)\n",
    "print(y[1,0:2,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0c9b1d-0fde-427a-877e-3582e5121844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.arange(20)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bed2c7-dd47-48b1-a2ab-04f04f020266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
