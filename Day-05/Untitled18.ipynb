{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cfa0c2-2e79-4086-b7ee-e31e03a2504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN(Convolutional Neural Network)\n",
    "\n",
    "CNN(Convolutional Neural Network) is a Specialized Deep Neural Network which is used for Processing\n",
    "Structured Grid Data such as images. CNNs are particularly powerful in tasks involving Image Recognition,\n",
    "Object Detection and computer vision etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f4c22b-3a09-46a3-bbd4-0a82bdbc9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "key components of CNN\n",
    "\n",
    "1) Convolutional layers\n",
    "2) Pooling Layers\n",
    "3) Activation Function\n",
    "4) Fully Connected Layers\n",
    "5) Dropout\n",
    "6) Softmax/Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27279b16-7c8a-43c4-aace-7e051c76667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Convolutional Layers\n",
    "\n",
    "Performs Convolutional operations using filters(Kernels) to detect local operations like edges, \n",
    "textures and shapes in the input image. Each filter produces a feature map highlighting specific patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bef02f-0aad-4e65-8cd3-2f38619c7963",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pooling Layers\n",
    "\n",
    "Reduces the spatial dimensions(height and width) of feature maps while retaining essential features.\n",
    "\n",
    "There are two types of Pooling Layers. They are:\n",
    "1) Max Pooling: Takes the Maximum Value of a Region.\n",
    "2) Average Pooling: Takes the Average Value of a Region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e60dc-a323-4966-aa32-a3ef072191c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Activation Functions\n",
    "\n",
    "Introduced after the convolutional to add non-linearity functions, to enable the network \n",
    "to learn complex patterns. Commom Activation Functions are Relu, Sigmoid and tanh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c64cf-f9a9-4ee5-9042-11747082cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fully Connected Layers\n",
    "\n",
    "Flattens the feature maps into a vector and connects them to a dense layer for final\n",
    "classification or regression. Combines Features extracted by earlier layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45723ca5-9268-41a9-89dc-e8e720ea0d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropout \n",
    "\n",
    "Reduces overfitting by randomly setting a fraction of neurons and outputs to zero during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186526da-d39c-427f-9400-4ca52759c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Softmax/Output Layer\n",
    "\n",
    "Converts the output into probabilities for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087925e0-19e2-459a-832a-6d46fca22a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "key concepts of CNN Workflow\n",
    "\n",
    "Input Layer:\n",
    "Accepts Raw Data(such as images)\n",
    "\n",
    "Feature Extraction:\n",
    "Uses Convolutional and Pooling Layers to extract the features.\n",
    "\n",
    "Flattening:\n",
    "Converts Extracted Features into an One-Dimensional Array.\n",
    "\n",
    "Classification:\n",
    "Processess features in fully connected layers for Prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88135bfa-593c-4d64-95db-56c6ec7cca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "Application of CNNs\n",
    "\n",
    "1) Image Classification and Segmentation\n",
    "2) Object Detection \n",
    "3) Computer Vision\n",
    "4) Video Analysis\n",
    "5) Face Recognition\n",
    "6) Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0aeba2-e78b-4ca1-bad6-e659ae4a9b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lets go with example codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9fa248d-06d8-4688-b063-0759dcf408e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 58s 7ms/step - loss: 0.1277 - accuracy: 0.9604 - val_loss: 0.0771 - val_accuracy: 0.9773\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 57s 7ms/step - loss: 0.0477 - accuracy: 0.9851 - val_loss: 0.0527 - val_accuracy: 0.9852\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 59s 7ms/step - loss: 0.0326 - accuracy: 0.9895 - val_loss: 0.0449 - val_accuracy: 0.9877\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 57s 7ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.0536 - val_accuracy: 0.9854\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 58s 7ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.0512 - val_accuracy: 0.9870\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 58s 7ms/step - loss: 0.0161 - accuracy: 0.9950 - val_loss: 0.0685 - val_accuracy: 0.9835\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 59s 7ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0486 - val_accuracy: 0.9878\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 59s 7ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.0467 - val_accuracy: 0.9907\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 59s 7ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.0496 - val_accuracy: 0.9901\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 59s 7ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.0674 - val_accuracy: 0.9868\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0632 - accuracy: 0.9882\n",
      "Loss: 0.06316741555929184,Accuracy: 0.9882000088691711\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "x_train=x_train.reshape((x_train.shape[0],28,28,1)).astype('float32')/255\n",
    "x_test=x_test.reshape((x_test.shape[0],28,28,1)).astype('float32')/255\n",
    "y_train=to_categorical(y_train,10)\n",
    "y_test=to_categorical(y_test,10)\n",
    "model=models.Sequential([layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "                        layers.MaxPooling2D((2,2)),\n",
    "                        layers.Conv2D(64,(3,3),activation='relu'),layers.MaxPooling2D((2,2)),\n",
    "                        layers.Flatten(),\n",
    "                        layers.Dense(64,activation='relu'),layers.Dense(10,activation='sigmoid')])\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=10,batch_size=6,validation_split=0.2)\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(f'Loss: {loss},Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c566d79d-4726-4daa-871f-84400bd16cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 25s 48ms/step - loss: 1.5803 - accuracy: 0.4271 - val_loss: 1.3397 - val_accuracy: 0.5250\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 25s 50ms/step - loss: 1.2528 - accuracy: 0.5587 - val_loss: 1.2174 - val_accuracy: 0.5787\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 26s 51ms/step - loss: 1.1072 - accuracy: 0.6131 - val_loss: 1.0801 - val_accuracy: 0.6309\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 26s 52ms/step - loss: 1.0042 - accuracy: 0.6516 - val_loss: 1.0203 - val_accuracy: 0.6513\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 25s 50ms/step - loss: 0.9432 - accuracy: 0.6741 - val_loss: 0.9983 - val_accuracy: 0.6680\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 25s 50ms/step - loss: 0.8929 - accuracy: 0.6906 - val_loss: 0.9896 - val_accuracy: 0.6596\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 25s 49ms/step - loss: 0.8413 - accuracy: 0.7105 - val_loss: 0.9515 - val_accuracy: 0.6768\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 24s 48ms/step - loss: 0.7951 - accuracy: 0.7238 - val_loss: 0.9386 - val_accuracy: 0.6835\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 24s 48ms/step - loss: 0.7593 - accuracy: 0.7354 - val_loss: 0.9419 - val_accuracy: 0.6838\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 24s 48ms/step - loss: 0.7164 - accuracy: 0.7510 - val_loss: 0.9057 - val_accuracy: 0.6995\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.9048 - accuracy: 0.6956\n",
      "Loss: 0.6955999732017517, Accuracy: 0.6955999732017517\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
    "x_train=x_train.astype('float32')/255\n",
    "x_test=x_test.astype('float32')/255\n",
    "y_train=to_categorical(y_train,10)\n",
    "y_test=to_categorical(y_test,10)\n",
    "model=models.Sequential([layers.Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)),\n",
    "                         layers.MaxPooling2D((2,2)),\n",
    "                         layers.Conv2D(64,(3,3),activation='relu'),layers.MaxPooling2D((2,2)),\n",
    "                         layers.Flatten(),\n",
    "                         layers.Dense(64,activation='relu'),layers.Dense(10,activation='sigmoid')])\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=10,batch_size=80,validation_split=0.2)\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(f'Loss: {accuracy}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0354e204-ba89-42de-ba6e-b2d54b31e990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.2040 - accuracy: 0.9429 - val_loss: 0.2275 - val_accuracy: 0.9331\n",
      "Epoch 2/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1882 - accuracy: 0.9431 - val_loss: 0.2083 - val_accuracy: 0.9331\n",
      "Epoch 3/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1833 - accuracy: 0.9431 - val_loss: 0.2238 - val_accuracy: 0.9331\n",
      "Epoch 4/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1799 - accuracy: 0.9434 - val_loss: 0.2051 - val_accuracy: 0.9331\n",
      "Epoch 5/50\n",
      "1645/1645 [==============================] - 5s 3ms/step - loss: 0.1769 - accuracy: 0.9437 - val_loss: 0.2185 - val_accuracy: 0.9275\n",
      "Epoch 6/50\n",
      "1645/1645 [==============================] - 6s 3ms/step - loss: 0.1755 - accuracy: 0.9440 - val_loss: 0.2057 - val_accuracy: 0.9331\n",
      "Epoch 7/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1707 - accuracy: 0.9445 - val_loss: 0.2280 - val_accuracy: 0.9340\n",
      "Epoch 8/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.1692 - accuracy: 0.9444 - val_loss: 0.2201 - val_accuracy: 0.9348\n",
      "Epoch 9/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1661 - accuracy: 0.9452 - val_loss: 0.2090 - val_accuracy: 0.9340\n",
      "Epoch 10/50\n",
      "1645/1645 [==============================] - 6s 3ms/step - loss: 0.1617 - accuracy: 0.9457 - val_loss: 0.2242 - val_accuracy: 0.9327\n",
      "Epoch 11/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1595 - accuracy: 0.9455 - val_loss: 0.2104 - val_accuracy: 0.9335\n",
      "Epoch 12/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1582 - accuracy: 0.9459 - val_loss: 0.2172 - val_accuracy: 0.9348\n",
      "Epoch 13/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.1551 - accuracy: 0.9461 - val_loss: 0.2240 - val_accuracy: 0.9348\n",
      "Epoch 14/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1512 - accuracy: 0.9462 - val_loss: 0.2479 - val_accuracy: 0.9348\n",
      "Epoch 15/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1486 - accuracy: 0.9461 - val_loss: 0.2452 - val_accuracy: 0.9352\n",
      "Epoch 16/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1438 - accuracy: 0.9461 - val_loss: 0.2577 - val_accuracy: 0.9344\n",
      "Epoch 17/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1386 - accuracy: 0.9471 - val_loss: 0.2448 - val_accuracy: 0.9344\n",
      "Epoch 18/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1360 - accuracy: 0.9483 - val_loss: 0.2670 - val_accuracy: 0.9323\n",
      "Epoch 19/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1306 - accuracy: 0.9500 - val_loss: 0.2612 - val_accuracy: 0.9295\n",
      "Epoch 20/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.1289 - accuracy: 0.9501 - val_loss: 0.2841 - val_accuracy: 0.9186\n",
      "Epoch 21/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1230 - accuracy: 0.9519 - val_loss: 0.2909 - val_accuracy: 0.9283\n",
      "Epoch 22/50\n",
      "1645/1645 [==============================] - 6s 3ms/step - loss: 0.1173 - accuracy: 0.9522 - val_loss: 0.3308 - val_accuracy: 0.9279\n",
      "Epoch 23/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1156 - accuracy: 0.9519 - val_loss: 0.3319 - val_accuracy: 0.9238\n",
      "Epoch 24/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1107 - accuracy: 0.9547 - val_loss: 0.3350 - val_accuracy: 0.9242\n",
      "Epoch 25/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1072 - accuracy: 0.9549 - val_loss: 0.3560 - val_accuracy: 0.9218\n",
      "Epoch 26/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.1028 - accuracy: 0.9569 - val_loss: 0.3771 - val_accuracy: 0.9287\n",
      "Epoch 27/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.1018 - accuracy: 0.9596 - val_loss: 0.4231 - val_accuracy: 0.9190\n",
      "Epoch 28/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.0977 - accuracy: 0.9595 - val_loss: 0.4212 - val_accuracy: 0.9234\n",
      "Epoch 29/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.0934 - accuracy: 0.9603 - val_loss: 0.3706 - val_accuracy: 0.9088\n",
      "Epoch 30/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.0911 - accuracy: 0.9625 - val_loss: 0.4206 - val_accuracy: 0.9186\n",
      "Epoch 31/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.0863 - accuracy: 0.9646 - val_loss: 0.4513 - val_accuracy: 0.9060\n",
      "Epoch 32/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.0824 - accuracy: 0.9660 - val_loss: 0.5122 - val_accuracy: 0.9141\n",
      "Epoch 33/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.0851 - accuracy: 0.9652 - val_loss: 0.5248 - val_accuracy: 0.9165\n",
      "Epoch 34/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.0798 - accuracy: 0.9661 - val_loss: 0.4989 - val_accuracy: 0.9145\n",
      "Epoch 35/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.0781 - accuracy: 0.9672 - val_loss: 0.6500 - val_accuracy: 0.9165\n",
      "Epoch 36/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.0748 - accuracy: 0.9686 - val_loss: 0.5634 - val_accuracy: 0.9080\n",
      "Epoch 37/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.0713 - accuracy: 0.9711 - val_loss: 0.4968 - val_accuracy: 0.8951\n",
      "Epoch 38/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.0715 - accuracy: 0.9700 - val_loss: 0.5701 - val_accuracy: 0.9015\n",
      "Epoch 39/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.0675 - accuracy: 0.9719 - val_loss: 0.7283 - val_accuracy: 0.9117\n",
      "Epoch 40/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.0631 - accuracy: 0.9729 - val_loss: 0.6821 - val_accuracy: 0.8999\n",
      "Epoch 41/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.0703 - accuracy: 0.9737 - val_loss: 0.7016 - val_accuracy: 0.9182\n",
      "Epoch 42/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.0586 - accuracy: 0.9745 - val_loss: 0.7074 - val_accuracy: 0.9161\n",
      "Epoch 43/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.0574 - accuracy: 0.9749 - val_loss: 0.7814 - val_accuracy: 0.9153\n",
      "Epoch 44/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.0568 - accuracy: 0.9779 - val_loss: 0.7519 - val_accuracy: 0.9117\n",
      "Epoch 45/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.0542 - accuracy: 0.9780 - val_loss: 0.7867 - val_accuracy: 0.9105\n",
      "Epoch 46/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.0541 - accuracy: 0.9770 - val_loss: 0.8158 - val_accuracy: 0.9088\n",
      "Epoch 47/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.0515 - accuracy: 0.9792 - val_loss: 0.8939 - val_accuracy: 0.9007\n",
      "Epoch 48/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.0505 - accuracy: 0.9821 - val_loss: 0.9486 - val_accuracy: 0.9202\n",
      "Epoch 49/50\n",
      "1645/1645 [==============================] - 6s 4ms/step - loss: 0.0483 - accuracy: 0.9814 - val_loss: 0.8431 - val_accuracy: 0.9056\n",
      "Epoch 50/50\n",
      "1645/1645 [==============================] - 7s 4ms/step - loss: 0.0533 - accuracy: 0.9782 - val_loss: 0.9013 - val_accuracy: 0.9149\n",
      "97/97 [==============================] - 0s 3ms/step - loss: 0.8650 - accuracy: 0.9196\n",
      "Loss: 0.8650227189064026,Accuracy: 0.9195849299430847\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "data=pd.read_csv('data.csv')\n",
    "if 'FraudFound_P' in data.columns:\n",
    "    X=data.drop(columns=('FraudFound_P'))\n",
    "    y=data['FraudFound_P']\n",
    "else:\n",
    "    print('FraudFound_P is not in the Dataset')\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "X_scaled=X_scaled.reshape((X_scaled.shape[0],X_scaled.shape[1],1,1))\n",
    "encoder=LabelEncoder()\n",
    "y=encoder.fit_transform(y)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=0.2,random_state=42)\n",
    "X_train=X_train.reshape((X_train.shape[0],X_train.shape[1],1,1))\n",
    "X_test=X_test.reshape((X_test.shape[0],X_test.shape[1],1,1))\n",
    "model=models.Sequential([layers.Conv2D(64,(3,1),activation='relu',input_shape=(X_train.shape[1],1,1)),\n",
    "                         layers.MaxPooling2D((1,1)),layers.Conv2D(128,(3,1),activation='relu'),\n",
    "                         layers.MaxPooling2D((1,1)),layers.Flatten(),\n",
    "                         layers.Dense(64,activation='relu'),layers.Dense(len(np.unique(y)),activation='softmax')])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=50,batch_size=6,validation_split=0.2)\n",
    "loss,accuracy=model.evaluate(X_test,y_test)\n",
    "print(f'Loss: {loss},Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2aa7419f-9ee0-4467-9d4e-9feba05e0676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "88/88 [==============================] - 1s 4ms/step - loss: 1.7723 - accuracy: 0.5703 - val_loss: 0.6850 - val_accuracy: 0.8153\n",
      "Epoch 2/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.3301 - accuracy: 0.9041 - val_loss: 0.2551 - val_accuracy: 0.9148\n",
      "Epoch 3/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.1767 - accuracy: 0.9510 - val_loss: 0.1573 - val_accuracy: 0.9460\n",
      "Epoch 4/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.1191 - accuracy: 0.9574 - val_loss: 0.1426 - val_accuracy: 0.9403\n",
      "Epoch 5/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.1140 - accuracy: 0.9553 - val_loss: 0.0999 - val_accuracy: 0.9744\n",
      "Epoch 6/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0945 - accuracy: 0.9680 - val_loss: 0.1003 - val_accuracy: 0.9659\n",
      "Epoch 7/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0660 - accuracy: 0.9780 - val_loss: 0.0950 - val_accuracy: 0.9659\n",
      "Epoch 8/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9723 - val_loss: 0.0914 - val_accuracy: 0.9574\n",
      "Epoch 9/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9780 - val_loss: 0.0936 - val_accuracy: 0.9545\n",
      "Epoch 10/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9794 - val_loss: 0.0799 - val_accuracy: 0.9744\n",
      "Epoch 11/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9751 - val_loss: 0.1301 - val_accuracy: 0.9659\n",
      "Epoch 12/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9837 - val_loss: 0.0802 - val_accuracy: 0.9602\n",
      "Epoch 13/30\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9872 - val_loss: 0.0639 - val_accuracy: 0.9858\n",
      "Epoch 14/30\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9879 - val_loss: 0.0685 - val_accuracy: 0.9801\n",
      "Epoch 15/30\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.0348 - accuracy: 0.9858 - val_loss: 0.3700 - val_accuracy: 0.9432\n",
      "Epoch 16/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.1093 - accuracy: 0.9688 - val_loss: 0.0653 - val_accuracy: 0.9744\n",
      "Epoch 17/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9886 - val_loss: 0.0613 - val_accuracy: 0.9830\n",
      "Epoch 18/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.1245 - val_accuracy: 0.9545\n",
      "Epoch 19/30\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.9915 - val_loss: 0.0949 - val_accuracy: 0.9602\n",
      "Epoch 20/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 0.0595 - val_accuracy: 0.9830\n",
      "Epoch 21/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.0723 - val_accuracy: 0.9688\n",
      "Epoch 22/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9915 - val_loss: 0.0727 - val_accuracy: 0.9801\n",
      "Epoch 23/30\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9908 - val_loss: 0.0541 - val_accuracy: 0.9830\n",
      "Epoch 24/30\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.0637 - val_accuracy: 0.9744\n",
      "Epoch 25/30\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9943 - val_loss: 0.0877 - val_accuracy: 0.9574\n",
      "Epoch 26/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9929 - val_loss: 0.0665 - val_accuracy: 0.9716\n",
      "Epoch 27/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 0.9922 - val_loss: 0.1024 - val_accuracy: 0.9773\n",
      "Epoch 28/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9893 - val_loss: 0.1068 - val_accuracy: 0.9659\n",
      "Epoch 29/30\n",
      "88/88 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9901 - val_loss: 0.0669 - val_accuracy: 0.9886\n",
      "Epoch 30/30\n",
      "88/88 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0699 - val_accuracy: 0.9773\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.9705\n",
      "Loss: 0.09373440593481064,Accuracy: 0.9704545736312866\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "data=pd.read_csv('Crop_Yield_Prediction.csv')\n",
    "if 'Crop' in data.columns:\n",
    "    X=data.drop('Crop',axis=1)\n",
    "    y=data['Crop']\n",
    "else:\n",
    "    print('crop is not in the dataset')\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "encoder=LabelEncoder()\n",
    "y=encoder.fit_transform(y)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=0.2,random_state=42)\n",
    "X_train=X_train.reshape((X_train.shape[0],X_train.shape[1],1,1))\n",
    "X_test=X_test.reshape((X_test.shape[0],X_test.shape[1],1,1))\n",
    "model=models.Sequential([layers.Conv2D(64,(3,1),activation='relu',input_shape=(X_train.shape[1],1,1)),\n",
    "                         layers.MaxPooling2D((1,1)),layers.Conv2D(128,(3,1),activation='relu'),\n",
    "                         layers.MaxPooling2D((1,1)),layers.Flatten(),\n",
    "                         layers.Dense(64,activation='relu'),layers.Dense(len(np.unique(y)),activation='softmax')])\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=30,batch_size=16,validation_split=0.2)\n",
    "loss,accuracy=model.evaluate(X_test,y_test)\n",
    "print(f'Loss: {loss},Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ec9c7-cbce-46b6-98b3-637e6d92f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "These are the above examples for the CNN. Lets discuss the CNN Architectures step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8f6d8-1f00-49ee-a86c-8e245e71a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1) LeNet\n",
    "\n",
    "It was invented in 1998.\n",
    "LeNet uses two convolutional layers followed by average pooling.\n",
    "In LeNet we use tanh for activation function instead of Relu.\n",
    "It is a shallow model that performs well on mnist dataset and but complex on cifar10 because of complex on images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a0c3b-2dd1-4a18-8aa8-fe7baf7ec0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now we follow the example of Lenet is the first cnn architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a361e409-1444-48d7-ba48-ea26712fbda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 59s 7ms/step - loss: 0.1868 - accuracy: 0.9428 - val_loss: 0.0906 - val_accuracy: 0.9737\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 55s 7ms/step - loss: 0.0814 - accuracy: 0.9759 - val_loss: 0.0853 - val_accuracy: 0.9742\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 57s 7ms/step - loss: 0.0657 - accuracy: 0.9794 - val_loss: 0.0664 - val_accuracy: 0.9809\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 56s 7ms/step - loss: 0.0547 - accuracy: 0.9827 - val_loss: 0.0703 - val_accuracy: 0.9799\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 56s 7ms/step - loss: 0.0484 - accuracy: 0.9850 - val_loss: 0.0624 - val_accuracy: 0.9822\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 58s 7ms/step - loss: 0.0423 - accuracy: 0.9869 - val_loss: 0.0544 - val_accuracy: 0.9842\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 57s 7ms/step - loss: 0.0371 - accuracy: 0.9888 - val_loss: 0.0622 - val_accuracy: 0.9823\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 57s 7ms/step - loss: 0.0348 - accuracy: 0.9890 - val_loss: 0.0626 - val_accuracy: 0.9832\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 58s 7ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 0.0633 - val_accuracy: 0.9831\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 59s 7ms/step - loss: 0.0295 - accuracy: 0.9906 - val_loss: 0.0560 - val_accuracy: 0.9847\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.0501 - accuracy: 0.9854\n",
      "loss: 0.05011401325464249,Accuracy: 0.9854000210762024\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "x_train=tf.image.grayscale_to_rgb(tf.image.resize(x_train[...,tf.newaxis],(32, 32))).numpy()\n",
    "x_test=tf.image.grayscale_to_rgb(tf.image.resize(x_test[...,tf.newaxis],(32, 32))).numpy()\n",
    "x_train=x_train.astype('float32')/255\n",
    "x_test=x_test.astype('float32')/255\n",
    "y_train=to_categorical(y_train,10)\n",
    "y_test=to_categorical(y_test,10)\n",
    "model=models.Sequential([layers.Conv2D(6,(5,5),activation='tanh',input_shape=(32,32,3)),\n",
    "                         layers.AveragePooling2D(),layers.Conv2D(16,(5,5),activation='tanh'),\n",
    "                         layers.AveragePooling2D(),layers.Flatten(),\n",
    "                         layers.Dense(120,activation='tanh'),\n",
    "                         layers.Dense(84,activation='tanh'),\n",
    "                         layers.Dense(10,activation='softmax')])\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=10,batch_size=6,validation_split=0.2)\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(f'loss: {loss},Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1bb83eb-bd5c-4181-8cd4-97e73d6a0f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "625/625 [==============================] - 17s 26ms/step - loss: 1.8402 - accuracy: 0.3465 - val_loss: 1.7332 - val_accuracy: 0.3925\n",
      "Epoch 2/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 1.6628 - accuracy: 0.4130 - val_loss: 1.6164 - val_accuracy: 0.4321\n",
      "Epoch 3/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 1.5378 - accuracy: 0.4564 - val_loss: 1.5200 - val_accuracy: 0.4658\n",
      "Epoch 4/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 1.4437 - accuracy: 0.4882 - val_loss: 1.4451 - val_accuracy: 0.4931\n",
      "Epoch 5/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 1.3660 - accuracy: 0.5186 - val_loss: 1.4288 - val_accuracy: 0.4955\n",
      "Epoch 6/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 1.3119 - accuracy: 0.5354 - val_loss: 1.3933 - val_accuracy: 0.5094\n",
      "Epoch 7/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 1.2615 - accuracy: 0.5541 - val_loss: 1.3639 - val_accuracy: 0.5194\n",
      "Epoch 8/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 1.2155 - accuracy: 0.5722 - val_loss: 1.3511 - val_accuracy: 0.5283\n",
      "Epoch 9/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 1.1778 - accuracy: 0.5864 - val_loss: 1.3693 - val_accuracy: 0.5204\n",
      "Epoch 10/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 1.1423 - accuracy: 0.5982 - val_loss: 1.3491 - val_accuracy: 0.5326\n",
      "Epoch 11/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 1.1050 - accuracy: 0.6088 - val_loss: 1.3516 - val_accuracy: 0.5322\n",
      "Epoch 12/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 1.0788 - accuracy: 0.6223 - val_loss: 1.3507 - val_accuracy: 0.5256\n",
      "Epoch 13/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 1.0445 - accuracy: 0.6333 - val_loss: 1.3728 - val_accuracy: 0.5319\n",
      "Epoch 14/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 1.0171 - accuracy: 0.6423 - val_loss: 1.3894 - val_accuracy: 0.5320\n",
      "Epoch 15/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.9934 - accuracy: 0.6529 - val_loss: 1.3665 - val_accuracy: 0.5373\n",
      "Epoch 16/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.9623 - accuracy: 0.6615 - val_loss: 1.4118 - val_accuracy: 0.5318\n",
      "Epoch 17/100\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.9351 - accuracy: 0.6729 - val_loss: 1.3976 - val_accuracy: 0.5350\n",
      "Epoch 18/100\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.9124 - accuracy: 0.6809 - val_loss: 1.4134 - val_accuracy: 0.5347\n",
      "Epoch 19/100\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.8887 - accuracy: 0.6897 - val_loss: 1.4651 - val_accuracy: 0.5276\n",
      "Epoch 20/100\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.8632 - accuracy: 0.6978 - val_loss: 1.4548 - val_accuracy: 0.5325\n",
      "Epoch 21/100\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.8432 - accuracy: 0.7057 - val_loss: 1.4823 - val_accuracy: 0.5287\n",
      "Epoch 22/100\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.8189 - accuracy: 0.7152 - val_loss: 1.4800 - val_accuracy: 0.5307\n",
      "Epoch 23/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.7959 - accuracy: 0.7226 - val_loss: 1.4897 - val_accuracy: 0.5317\n",
      "Epoch 24/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.7775 - accuracy: 0.7270 - val_loss: 1.5327 - val_accuracy: 0.5242\n",
      "Epoch 25/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.7556 - accuracy: 0.7377 - val_loss: 1.5395 - val_accuracy: 0.5295\n",
      "Epoch 26/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.7317 - accuracy: 0.7467 - val_loss: 1.5676 - val_accuracy: 0.5217\n",
      "Epoch 27/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.7150 - accuracy: 0.7525 - val_loss: 1.5882 - val_accuracy: 0.5207\n",
      "Epoch 28/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.6960 - accuracy: 0.7580 - val_loss: 1.6220 - val_accuracy: 0.5173\n",
      "Epoch 29/100\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.6767 - accuracy: 0.7638 - val_loss: 1.6429 - val_accuracy: 0.5192\n",
      "Epoch 30/100\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.6587 - accuracy: 0.7717 - val_loss: 1.6663 - val_accuracy: 0.5202\n",
      "Epoch 31/100\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.6394 - accuracy: 0.7781 - val_loss: 1.6915 - val_accuracy: 0.5160\n",
      "Epoch 32/100\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.6226 - accuracy: 0.7854 - val_loss: 1.7323 - val_accuracy: 0.5101\n",
      "Epoch 33/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.6042 - accuracy: 0.7902 - val_loss: 1.7444 - val_accuracy: 0.5128\n",
      "Epoch 34/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.5878 - accuracy: 0.7977 - val_loss: 1.7840 - val_accuracy: 0.5059\n",
      "Epoch 35/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.5708 - accuracy: 0.8045 - val_loss: 1.8079 - val_accuracy: 0.5085\n",
      "Epoch 36/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.5552 - accuracy: 0.8088 - val_loss: 1.8467 - val_accuracy: 0.5089\n",
      "Epoch 37/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.5417 - accuracy: 0.8135 - val_loss: 1.8416 - val_accuracy: 0.5112\n",
      "Epoch 38/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.5218 - accuracy: 0.8216 - val_loss: 1.8954 - val_accuracy: 0.5052\n",
      "Epoch 39/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.5054 - accuracy: 0.8284 - val_loss: 1.9372 - val_accuracy: 0.5050\n",
      "Epoch 40/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.4953 - accuracy: 0.8323 - val_loss: 1.9669 - val_accuracy: 0.5018\n",
      "Epoch 41/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.4760 - accuracy: 0.8378 - val_loss: 1.9837 - val_accuracy: 0.5074\n",
      "Epoch 42/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.4696 - accuracy: 0.8414 - val_loss: 2.0275 - val_accuracy: 0.5059\n",
      "Epoch 43/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.4503 - accuracy: 0.8470 - val_loss: 2.0721 - val_accuracy: 0.5050\n",
      "Epoch 44/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.4389 - accuracy: 0.8523 - val_loss: 2.0889 - val_accuracy: 0.5006\n",
      "Epoch 45/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.4208 - accuracy: 0.8585 - val_loss: 2.1304 - val_accuracy: 0.4980\n",
      "Epoch 46/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.4087 - accuracy: 0.8619 - val_loss: 2.1781 - val_accuracy: 0.4996\n",
      "Epoch 47/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.4001 - accuracy: 0.8655 - val_loss: 2.2011 - val_accuracy: 0.5015\n",
      "Epoch 48/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.3890 - accuracy: 0.8683 - val_loss: 2.2363 - val_accuracy: 0.4939\n",
      "Epoch 49/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.3740 - accuracy: 0.8749 - val_loss: 2.2716 - val_accuracy: 0.5019\n",
      "Epoch 50/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.3627 - accuracy: 0.8773 - val_loss: 2.3055 - val_accuracy: 0.4989\n",
      "Epoch 51/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.3546 - accuracy: 0.8825 - val_loss: 2.3526 - val_accuracy: 0.4948\n",
      "Epoch 52/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.3414 - accuracy: 0.8860 - val_loss: 2.3511 - val_accuracy: 0.4952\n",
      "Epoch 53/100\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.3312 - accuracy: 0.8899 - val_loss: 2.4205 - val_accuracy: 0.4905\n",
      "Epoch 54/100\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.3235 - accuracy: 0.8932 - val_loss: 2.4574 - val_accuracy: 0.4916\n",
      "Epoch 55/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.3153 - accuracy: 0.8945 - val_loss: 2.4966 - val_accuracy: 0.4909\n",
      "Epoch 56/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.2961 - accuracy: 0.9037 - val_loss: 2.5476 - val_accuracy: 0.4905\n",
      "Epoch 57/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.2958 - accuracy: 0.9023 - val_loss: 2.5724 - val_accuracy: 0.4929\n",
      "Epoch 58/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.2834 - accuracy: 0.9060 - val_loss: 2.5876 - val_accuracy: 0.4892\n",
      "Epoch 59/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.2763 - accuracy: 0.9089 - val_loss: 2.6448 - val_accuracy: 0.4857\n",
      "Epoch 60/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.2623 - accuracy: 0.9151 - val_loss: 2.7002 - val_accuracy: 0.4914\n",
      "Epoch 61/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.2548 - accuracy: 0.9174 - val_loss: 2.6922 - val_accuracy: 0.4907\n",
      "Epoch 62/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.2478 - accuracy: 0.9188 - val_loss: 2.7796 - val_accuracy: 0.4906\n",
      "Epoch 63/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.2494 - accuracy: 0.9183 - val_loss: 2.7872 - val_accuracy: 0.4881\n",
      "Epoch 64/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.2356 - accuracy: 0.9235 - val_loss: 2.8198 - val_accuracy: 0.4813\n",
      "Epoch 65/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.2328 - accuracy: 0.9240 - val_loss: 2.8668 - val_accuracy: 0.4837\n",
      "Epoch 66/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.2136 - accuracy: 0.9317 - val_loss: 2.9089 - val_accuracy: 0.4888\n",
      "Epoch 67/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.2139 - accuracy: 0.9326 - val_loss: 2.9736 - val_accuracy: 0.4811\n",
      "Epoch 68/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.2224 - accuracy: 0.9276 - val_loss: 2.9766 - val_accuracy: 0.4838\n",
      "Epoch 69/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.2065 - accuracy: 0.9341 - val_loss: 3.0049 - val_accuracy: 0.4848\n",
      "Epoch 70/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1921 - accuracy: 0.9400 - val_loss: 3.0893 - val_accuracy: 0.4832\n",
      "Epoch 71/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1942 - accuracy: 0.9380 - val_loss: 3.0575 - val_accuracy: 0.4846\n",
      "Epoch 72/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1946 - accuracy: 0.9377 - val_loss: 3.1379 - val_accuracy: 0.4866\n",
      "Epoch 73/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1800 - accuracy: 0.9437 - val_loss: 3.1800 - val_accuracy: 0.4828\n",
      "Epoch 74/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.1830 - accuracy: 0.9419 - val_loss: 3.1983 - val_accuracy: 0.4841\n",
      "Epoch 75/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1800 - accuracy: 0.9419 - val_loss: 3.2354 - val_accuracy: 0.4862\n",
      "Epoch 76/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.1640 - accuracy: 0.9478 - val_loss: 3.2832 - val_accuracy: 0.4821\n",
      "Epoch 77/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1752 - accuracy: 0.9434 - val_loss: 3.3300 - val_accuracy: 0.4818\n",
      "Epoch 78/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.1658 - accuracy: 0.9473 - val_loss: 3.3206 - val_accuracy: 0.4822\n",
      "Epoch 79/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.1661 - accuracy: 0.9464 - val_loss: 3.4041 - val_accuracy: 0.4772\n",
      "Epoch 80/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.1471 - accuracy: 0.9549 - val_loss: 3.4167 - val_accuracy: 0.4835\n",
      "Epoch 81/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.1449 - accuracy: 0.9549 - val_loss: 3.4380 - val_accuracy: 0.4813\n",
      "Epoch 82/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1615 - accuracy: 0.9487 - val_loss: 3.4487 - val_accuracy: 0.4863\n",
      "Epoch 83/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1489 - accuracy: 0.9524 - val_loss: 3.4820 - val_accuracy: 0.4803\n",
      "Epoch 84/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.1404 - accuracy: 0.9554 - val_loss: 3.5062 - val_accuracy: 0.4838\n",
      "Epoch 85/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1317 - accuracy: 0.9603 - val_loss: 3.6159 - val_accuracy: 0.4776\n",
      "Epoch 86/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.1446 - accuracy: 0.9540 - val_loss: 3.5995 - val_accuracy: 0.4839\n",
      "Epoch 87/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1366 - accuracy: 0.9564 - val_loss: 3.6629 - val_accuracy: 0.4803\n",
      "Epoch 88/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1451 - accuracy: 0.9527 - val_loss: 3.6705 - val_accuracy: 0.4822\n",
      "Epoch 89/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1395 - accuracy: 0.9546 - val_loss: 3.6710 - val_accuracy: 0.4796\n",
      "Epoch 90/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1175 - accuracy: 0.9636 - val_loss: 3.7185 - val_accuracy: 0.4785\n",
      "Epoch 91/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1074 - accuracy: 0.9689 - val_loss: 3.7663 - val_accuracy: 0.4803\n",
      "Epoch 92/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1386 - accuracy: 0.9537 - val_loss: 3.7748 - val_accuracy: 0.4744\n",
      "Epoch 93/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1365 - accuracy: 0.9563 - val_loss: 3.7962 - val_accuracy: 0.4734\n",
      "Epoch 94/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.1211 - accuracy: 0.9616 - val_loss: 3.8259 - val_accuracy: 0.4746\n",
      "Epoch 95/100\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.1217 - accuracy: 0.9606 - val_loss: 3.8612 - val_accuracy: 0.4783\n",
      "Epoch 96/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.1285 - accuracy: 0.9570 - val_loss: 3.8733 - val_accuracy: 0.4779\n",
      "Epoch 97/100\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.1301 - accuracy: 0.9582 - val_loss: 3.9190 - val_accuracy: 0.4745\n",
      "Epoch 98/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.0933 - accuracy: 0.9730 - val_loss: 3.9608 - val_accuracy: 0.4737\n",
      "Epoch 99/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.0955 - accuracy: 0.9724 - val_loss: 4.0123 - val_accuracy: 0.4715\n",
      "Epoch 100/100\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.1410 - accuracy: 0.9519 - val_loss: 4.0033 - val_accuracy: 0.4742\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 3.9948 - accuracy: 0.4745\n",
      "Loss: 3.9947831630706787, Accuracy: 0.47450000047683716\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
    "x_train=x_train.astype('float32')/255\n",
    "x_test=x_test.astype('float32')/255\n",
    "y_train=to_categorical(y_train,10)\n",
    "y_test=to_categorical(y_test,10)\n",
    "model=models.Sequential([layers.Conv2D(6,(5,5),activation='tanh',input_shape=(32,32,3)),\n",
    "                         layers.AveragePooling2D(),layers.Conv2D(16,(5,5),activation='tanh'),\n",
    "                         layers.AveragePooling2D(),layers.Flatten(),\n",
    "                         layers.Dense(120,activation='tanh'),\n",
    "                         layers.Dense(84,activation='tanh'),\n",
    "                         layers.Dense(10,activation='softmax')])\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=100,batch_size=64,validation_split=0.2)\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bfaa1c-be5f-41e0-9c88-66cbe8245aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hence it is known as CNN and LeNet CNN Architecture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
