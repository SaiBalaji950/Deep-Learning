{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f560e41d-8078-4abe-b699-da329e768ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "FeedForward Neural Networks\n",
    "\n",
    "A FeedForward Neural Network(FNN) is the simplest type of the Artificial Neural Networks(ANN). \n",
    "it is called the 'feedforward' because the flow of data only in one direction - from the input layer\n",
    "through hidden layer to the output layer. There are no cycles or loops in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d92f2-c18c-4346-98dd-54c99badbd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "Architecture of FNN\n",
    "\n",
    "1) Input Layer\n",
    "\n",
    "The first layer where raw data is input into the network.\n",
    "Each node represents one feature from the input data.\n",
    "\n",
    "2) Hidden Layer\n",
    "\n",
    "one or more layers between the input and output layers.\n",
    "nodes in these layers transform the input using weights, biases and activation functions.\n",
    "These layers enable the network to learn complex patterns.\n",
    "\n",
    "3) Output Layer\n",
    "\n",
    "The final layer of the network.\n",
    "produces the desired output like classification labels and regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d807e6-14aa-442d-9a01-257c443cf743",
   "metadata": {},
   "outputs": [],
   "source": [
    "How it works\n",
    "\n",
    "1) Forward Propagation\n",
    "\n",
    "Data flows foward from the input layer through the hidden layer to the output layer.\n",
    "At each neuron:\n",
    "z=w.x+b\n",
    "where w=weights\n",
    "      x=inputs\n",
    "      b=bias\n",
    "\n",
    "the result is z is passes to activation function to introduce non-linearity.\n",
    "a=activation(z)\n",
    "this process is repeated all process in the networks.\n",
    "\n",
    "\n",
    "2) Loss Function\n",
    "\n",
    "calculate the error between the predicted values and actual values.\n",
    "\n",
    "Mean Squared Error for regression tasks and cross entropy for classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36de6d0-247b-4db4-9040-9200ff5e7bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "3) Backpropagation\n",
    "\n",
    "The Error calculated by the loss function is propogated backword to adjust the weights and biases.\n",
    "uses the gradient descent algorithm to minimize the loss function.\n",
    "\n",
    "w=w-η.(∂Loss/ ∂w) where n= learning rate\n",
    "\n",
    "4) Weight update\n",
    "\n",
    "Adjusting Weights and biases improves the model accuracy over multiple iterations(epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0acffcbd-26cc-4940-b23d-d060ff840935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3/3 [==============================] - 1s 4ms/step - loss: 0.7072 - accuracy: 0.3750\n",
      "Epoch 2/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7052 - accuracy: 0.3875\n",
      "Epoch 3/15\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7038 - accuracy: 0.3875\n",
      "Epoch 4/15\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.7025 - accuracy: 0.4000\n",
      "Epoch 5/15\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.7011 - accuracy: 0.4000\n",
      "Epoch 6/15\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.7001 - accuracy: 0.4125\n",
      "Epoch 7/15\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.4250\n",
      "Epoch 8/15\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.4000\n",
      "Epoch 9/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6972 - accuracy: 0.4375\n",
      "Epoch 10/15\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6964 - accuracy: 0.4250\n",
      "Epoch 11/15\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.4750\n",
      "Epoch 12/15\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.4750\n",
      "Epoch 13/15\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5125\n",
      "Epoch 14/15\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5375\n",
      "Epoch 15/15\n",
      "3/3 [==============================] - 0s 0s/step - loss: 0.6932 - accuracy: 0.5625\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.6863 - accuracy: 0.5000\n",
      "Loss:0.6862806081771851,Accuracy:0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=np.random.rand(100,4)\n",
    "y=np.random.randint(0,2,size=(100,1))\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "model=Sequential()\n",
    "model.add(Dense(units=8,activation='relu',input_dim=4))\n",
    "model.add(Dense(units=16,activation='relu'))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=15,batch_size=32)\n",
    "loss, accuracy = model.evaluate(X_test,y_test)\n",
    "print(f'Loss:{loss},Accuracy:{accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "024586de-a449-492b-8f3f-dd0508017644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 3ms/step - loss: 0.7772 - accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7312 - accuracy: 0.3417\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.3500\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6589 - accuracy: 0.3833\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.4000\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.4250\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.4750\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.5250\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.6333\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7417\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8417\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.9333\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.9500\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.9667\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.9833\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.9917\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3369 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3033 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2718 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2427 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1924 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1424 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1337 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1183 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1111 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0989 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 930us/step - loss: 0.0931 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 645us/step - loss: 0.0566 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0440 - accuracy: 1.0000\n",
      "loss:0.04403363913297653,Accuracy:1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "iris=load_iris()\n",
    "X=iris.data\n",
    "y=iris.target\n",
    "y=np.where(y==0,1,0)\n",
    "scaler=StandardScaler()\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=0.2,random_state=42)\n",
    "model=Sequential()\n",
    "model.add(Dense(units=8,activation='relu',input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(units=16,activation='relu'))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=50,batch_size=16)\n",
    "loss,accuracy=model.evaluate(X_test,y_test)\n",
    "print(f'loss:{loss},Accuracy:{accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5ebdadd-325a-4c52-a159-d5c7a38b8154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0      842302         M        17.99         10.38          122.80     1001.0   \n",
       "1      842517         M        20.57         17.77          132.90     1326.0   \n",
       "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3    84348301         M        11.42         20.38           77.58      386.1   \n",
       "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
       "..        ...       ...          ...           ...             ...        ...   \n",
       "564    926424         M        21.56         22.39          142.00     1479.0   \n",
       "565    926682         M        20.13         28.25          131.20     1261.0   \n",
       "566    926954         M        16.60         28.08          108.30      858.1   \n",
       "567    927241         M        20.60         29.33          140.10     1265.0   \n",
       "568     92751         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0    ...          17.33           184.60      2019.0           0.16220   \n",
       "1    ...          23.41           158.80      1956.0           0.12380   \n",
       "2    ...          25.53           152.50      1709.0           0.14440   \n",
       "3    ...          26.50            98.87       567.7           0.20980   \n",
       "4    ...          16.67           152.20      1575.0           0.13740   \n",
       "..   ...            ...              ...         ...               ...   \n",
       "564  ...          26.40           166.10      2027.0           0.14100   \n",
       "565  ...          38.25           155.00      1731.0           0.11660   \n",
       "566  ...          34.12           126.70      1124.0           0.11390   \n",
       "567  ...          39.42           184.60      1821.0           0.16500   \n",
       "568  ...          30.37            59.16       268.6           0.08996   \n",
       "\n",
       "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0              0.66560           0.7119                0.2654          0.4601   \n",
       "1              0.18660           0.2416                0.1860          0.2750   \n",
       "2              0.42450           0.4504                0.2430          0.3613   \n",
       "3              0.86630           0.6869                0.2575          0.6638   \n",
       "4              0.20500           0.4000                0.1625          0.2364   \n",
       "..                 ...              ...                   ...             ...   \n",
       "564            0.21130           0.4107                0.2216          0.2060   \n",
       "565            0.19220           0.3215                0.1628          0.2572   \n",
       "566            0.30940           0.3403                0.1418          0.2218   \n",
       "567            0.86810           0.9387                0.2650          0.4087   \n",
       "568            0.06444           0.0000                0.0000          0.2871   \n",
       "\n",
       "     fractal_dimension_worst  Unnamed: 32  \n",
       "0                    0.11890          NaN  \n",
       "1                    0.08902          NaN  \n",
       "2                    0.08758          NaN  \n",
       "3                    0.17300          NaN  \n",
       "4                    0.07678          NaN  \n",
       "..                       ...          ...  \n",
       "564                  0.07115          NaN  \n",
       "565                  0.06637          NaN  \n",
       "566                  0.07820          NaN  \n",
       "567                  0.12400          NaN  \n",
       "568                  0.07039          NaN  \n",
       "\n",
       "[569 rows x 33 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Breastcancer.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ad2ab25-1226-4715-a6d1-f6e4e7342054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PythonTeam\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:985: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "C:\\Users\\PythonTeam\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:990: RuntimeWarning: invalid value encountered in true_divide\n",
      "  T = new_sum / new_sample_count\n",
      "C:\\Users\\PythonTeam\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:1020: RuntimeWarning: invalid value encountered in true_divide\n",
      "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29/29 [==============================] - 1s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 20/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 21/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 22/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 23/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 24/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 25/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 26/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 27/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 28/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 29/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 30/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 31/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 32/50\n",
      "29/29 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 33/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 34/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 35/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 36/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 37/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 38/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 39/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 40/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 41/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 42/50\n",
      "29/29 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 43/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 44/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 45/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 46/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 47/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 48/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 49/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "Epoch 50/50\n",
      "29/29 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.6286\n",
      "4/4 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.6228\n",
      "Loss: nan,Accuracy: 0.6228070259094238\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "data=pd.read_csv('Breastcancer.csv')\n",
    "if 'diagnosis' in data.columns:\n",
    "    X=data.drop('diagnosis',axis=1)\n",
    "    y=data['diagnosis']\n",
    "else:\n",
    "    print(\"The 'diagnosis' column is not found in the dataset.\")\n",
    "encoder=LabelEncoder()\n",
    "y=encoder.fit_transform(y)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "if X_train.isnull().any().any():\n",
    "    X_train = X_train.fillna(X_train.mean())\n",
    "if X_test.isnull().any().any():\n",
    "    X_test = X_test.fillna(X_test.mean())  \n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "model=Sequential()\n",
    "model.add(Dense(units=8,activation='relu',input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(units=16,activation='relu'))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=50,batch_size=16)\n",
    "loss,accuracy=model.evaluate(X_test,y_test)\n",
    "print(f'Loss: {loss},Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "977aec96-3d0d-48e4-bb0f-7f661e98d097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nitrogen</th>\n",
       "      <th>Phosphorus</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>pH_Value</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>20.879744</td>\n",
       "      <td>82.002744</td>\n",
       "      <td>6.502985</td>\n",
       "      <td>202.935536</td>\n",
       "      <td>Rice</td>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "      <td>21.770462</td>\n",
       "      <td>80.319644</td>\n",
       "      <td>7.038096</td>\n",
       "      <td>226.655537</td>\n",
       "      <td>Rice</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>23.004459</td>\n",
       "      <td>82.320763</td>\n",
       "      <td>7.840207</td>\n",
       "      <td>263.964248</td>\n",
       "      <td>Rice</td>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>26.491096</td>\n",
       "      <td>80.158363</td>\n",
       "      <td>6.980401</td>\n",
       "      <td>242.864034</td>\n",
       "      <td>Rice</td>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>20.130175</td>\n",
       "      <td>81.604873</td>\n",
       "      <td>7.628473</td>\n",
       "      <td>262.717340</td>\n",
       "      <td>Rice</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>107</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>26.774637</td>\n",
       "      <td>66.413269</td>\n",
       "      <td>6.780064</td>\n",
       "      <td>177.774507</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>99</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>27.417112</td>\n",
       "      <td>56.636362</td>\n",
       "      <td>6.086922</td>\n",
       "      <td>127.924610</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>118</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>24.131797</td>\n",
       "      <td>67.225123</td>\n",
       "      <td>6.362608</td>\n",
       "      <td>173.322839</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>117</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>26.272418</td>\n",
       "      <td>52.127394</td>\n",
       "      <td>6.758793</td>\n",
       "      <td>127.175293</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>104</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>23.603016</td>\n",
       "      <td>60.396475</td>\n",
       "      <td>6.779833</td>\n",
       "      <td>140.937041</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2200 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Nitrogen  Phosphorus  Potassium  Temperature   Humidity  pH_Value  \\\n",
       "0           90          42         43    20.879744  82.002744  6.502985   \n",
       "1           85          58         41    21.770462  80.319644  7.038096   \n",
       "2           60          55         44    23.004459  82.320763  7.840207   \n",
       "3           74          35         40    26.491096  80.158363  6.980401   \n",
       "4           78          42         42    20.130175  81.604873  7.628473   \n",
       "...        ...         ...        ...          ...        ...       ...   \n",
       "2195       107          34         32    26.774637  66.413269  6.780064   \n",
       "2196        99          15         27    27.417112  56.636362  6.086922   \n",
       "2197       118          33         30    24.131797  67.225123  6.362608   \n",
       "2198       117          32         34    26.272418  52.127394  6.758793   \n",
       "2199       104          18         30    23.603016  60.396475  6.779833   \n",
       "\n",
       "        Rainfall    Crop   Yield  \n",
       "0     202.935536    Rice    7000  \n",
       "1     226.655537    Rice    5000  \n",
       "2     263.964248    Rice    7000  \n",
       "3     242.864034    Rice    7000  \n",
       "4     262.717340    Rice  120000  \n",
       "...          ...     ...     ...  \n",
       "2195  177.774507  Coffee    1000  \n",
       "2196  127.924610  Coffee     800  \n",
       "2197  173.322839  Coffee     560  \n",
       "2198  127.175293  Coffee    1500  \n",
       "2199  140.937041  Coffee    1400  \n",
       "\n",
       "[2200 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('Crop_Yield_Prediction.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fbd8a2ed-fc7d-4439-a50a-d22d7bc5fc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "110/110 [==============================] - 1s 1ms/step - loss: -12.1415 - accuracy: 0.0540\n",
      "Epoch 2/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -57.3468 - accuracy: 0.0449\n",
      "Epoch 3/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -189.3224 - accuracy: 0.0449\n",
      "Epoch 4/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -491.0955 - accuracy: 0.0449\n",
      "Epoch 5/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -1080.0663 - accuracy: 0.0449\n",
      "Epoch 6/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -2040.8707 - accuracy: 0.0449\n",
      "Epoch 7/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -3442.3989 - accuracy: 0.0449\n",
      "Epoch 8/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -5345.6504 - accuracy: 0.0449\n",
      "Epoch 9/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -7813.5083 - accuracy: 0.0449\n",
      "Epoch 10/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -10900.5547 - accuracy: 0.0449\n",
      "Epoch 11/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -14647.9678 - accuracy: 0.0449\n",
      "Epoch 12/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -19087.8750 - accuracy: 0.0449\n",
      "Epoch 13/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -24256.5566 - accuracy: 0.0449\n",
      "Epoch 14/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -30201.4609 - accuracy: 0.0449\n",
      "Epoch 15/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -36920.7891 - accuracy: 0.0449\n",
      "Epoch 16/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -44447.1484 - accuracy: 0.0449\n",
      "Epoch 17/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -52808.7031 - accuracy: 0.0449\n",
      "Epoch 18/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -62032.6016 - accuracy: 0.0449\n",
      "Epoch 19/50\n",
      "110/110 [==============================] - 0s 2ms/step - loss: -72137.6953 - accuracy: 0.0449\n",
      "Epoch 20/50\n",
      "110/110 [==============================] - 0s 2ms/step - loss: -83124.5781 - accuracy: 0.0449\n",
      "Epoch 21/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -95062.7031 - accuracy: 0.0449\n",
      "Epoch 22/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -107942.9922 - accuracy: 0.0449\n",
      "Epoch 23/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -121785.1719 - accuracy: 0.0449\n",
      "Epoch 24/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -136584.1562 - accuracy: 0.0449\n",
      "Epoch 25/50\n",
      "110/110 [==============================] - 0s 2ms/step - loss: -152381.4062 - accuracy: 0.0449\n",
      "Epoch 26/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -169119.9531 - accuracy: 0.0449\n",
      "Epoch 27/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -186898.1406 - accuracy: 0.0449\n",
      "Epoch 28/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -205613.4688 - accuracy: 0.0449\n",
      "Epoch 29/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -225361.7656 - accuracy: 0.0449\n",
      "Epoch 30/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -246153.2031 - accuracy: 0.0449\n",
      "Epoch 31/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -268013.0312 - accuracy: 0.0449\n",
      "Epoch 32/50\n",
      "110/110 [==============================] - 0s 2ms/step - loss: -290953.8438 - accuracy: 0.0449\n",
      "Epoch 33/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -314980.8750 - accuracy: 0.0449\n",
      "Epoch 34/50\n",
      "110/110 [==============================] - 0s 2ms/step - loss: -340114.6562 - accuracy: 0.0449\n",
      "Epoch 35/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -366321.3750 - accuracy: 0.0449\n",
      "Epoch 36/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -393615.5000 - accuracy: 0.0449\n",
      "Epoch 37/50\n",
      "110/110 [==============================] - 0s 2ms/step - loss: -422019.9688 - accuracy: 0.0449\n",
      "Epoch 38/50\n",
      "110/110 [==============================] - 0s 2ms/step - loss: -451562.7500 - accuracy: 0.0449\n",
      "Epoch 39/50\n",
      "110/110 [==============================] - 0s 2ms/step - loss: -482275.7500 - accuracy: 0.0449\n",
      "Epoch 40/50\n",
      "110/110 [==============================] - 0s 2ms/step - loss: -514164.8438 - accuracy: 0.0449\n",
      "Epoch 41/50\n",
      "110/110 [==============================] - 0s 2ms/step - loss: -547147.4375 - accuracy: 0.0449\n",
      "Epoch 42/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -581372.7500 - accuracy: 0.0449\n",
      "Epoch 43/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -616654.3125 - accuracy: 0.0449\n",
      "Epoch 44/50\n",
      "110/110 [==============================] - 0s 2ms/step - loss: -653180.8125 - accuracy: 0.0449\n",
      "Epoch 45/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -690861.6250 - accuracy: 0.0449\n",
      "Epoch 46/50\n",
      "110/110 [==============================] - 0s 2ms/step - loss: -729852.1875 - accuracy: 0.0449\n",
      "Epoch 47/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -770079.5625 - accuracy: 0.0449\n",
      "Epoch 48/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -811732.1250 - accuracy: 0.0449\n",
      "Epoch 49/50\n",
      "110/110 [==============================] - 0s 1ms/step - loss: -854561.8750 - accuracy: 0.0449\n",
      "Epoch 50/50\n",
      "110/110 [==============================] - 0s 2ms/step - loss: -898800.3750 - accuracy: 0.0449\n",
      "14/14 [==============================] - 0s 1ms/step - loss: -879561.3125 - accuracy: 0.0477 \n",
      "Loss: -879561.3125,Accuracy: 0.04772727191448212\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "data=pd.read_csv('Crop_Yield_Prediction.csv')\n",
    "if 'Crop' in data.columns:\n",
    "    X=data.drop('Crop',axis=1)\n",
    "    y=data['Crop']\n",
    "else:\n",
    "    print(\"crop is not in the dataset\")\n",
    "encoder=LabelEncoder()\n",
    "y=encoder.fit_transform(y)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "if X_train.isnull().any().any():\n",
    "    X_train=X_train.fillna(X_train.mean())\n",
    "if X_test.isnull().any().any():\n",
    "    X_test=X_test.fillna(X_test.mean())\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "model=Sequential()\n",
    "model.add(Dense(units=8,activation='relu',input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(units=16,activation='relu'))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=50,batch_size=16)\n",
    "loss,accuracy=model.evaluate(X_test,y_test)\n",
    "print(f'Loss: {loss},Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db977194-2c97-46c2-a48a-f9c59a41980a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekOfMonth</th>\n",
       "      <th>Make</th>\n",
       "      <th>AccidentArea</th>\n",
       "      <th>DayOfWeekClaimed</th>\n",
       "      <th>WeekOfMonthClaimed</th>\n",
       "      <th>Sex</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fault</th>\n",
       "      <th>PolicyType</th>\n",
       "      <th>...</th>\n",
       "      <th>PastNumberOfClaims</th>\n",
       "      <th>AgeOfVehicle</th>\n",
       "      <th>AgeOfPolicyHolder</th>\n",
       "      <th>PoliceReportFiled</th>\n",
       "      <th>WitnessPresent</th>\n",
       "      <th>AgentType</th>\n",
       "      <th>NumberOfSuppliments</th>\n",
       "      <th>AddressChange_Claim</th>\n",
       "      <th>NumberOfCars</th>\n",
       "      <th>BasePolicy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15415</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15416</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15417</th>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15418</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15419</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15420 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       WeekOfMonth  Make  AccidentArea  DayOfWeekClaimed  WeekOfMonthClaimed  \\\n",
       "0                5     6             1                 6                   1   \n",
       "1                3     6             1                 2                   4   \n",
       "2                5     6             1                 5                   2   \n",
       "3                2    17             0                 1                   1   \n",
       "4                5     6             1                 6                   2   \n",
       "...            ...   ...           ...               ...                 ...   \n",
       "15415            4    17             1                 6                   5   \n",
       "15416            5    13             1                 1                   1   \n",
       "15417            5    17             0                 1                   1   \n",
       "15418            1    17             1                 5                   2   \n",
       "15419            2    17             1                 5                   3   \n",
       "\n",
       "       Sex  MaritalStatus   Age  Fault  PolicyType  ...  PastNumberOfClaims  \\\n",
       "0        0              2  21.0      0           5  ...                   3   \n",
       "1        1              2  34.0      0           4  ...                   3   \n",
       "2        1              1  47.0      0           4  ...                   0   \n",
       "3        1              1  65.0      1           2  ...                   0   \n",
       "4        0              2  27.0      1           4  ...                   3   \n",
       "...    ...            ...   ...    ...         ...  ...                 ...   \n",
       "15415    1              1  35.0      0           1  ...                   1   \n",
       "15416    1              1  30.0      0           2  ...                   2   \n",
       "15417    1              2  24.0      0           1  ...                   2   \n",
       "15418    0              1  34.0      1           0  ...                   3   \n",
       "15419    1              2  21.0      0           1  ...                   3   \n",
       "\n",
       "       AgeOfVehicle  AgeOfPolicyHolder  PoliceReportFiled  WitnessPresent  \\\n",
       "0                 1                  3                  0               0   \n",
       "1                 4                  4                  1               0   \n",
       "2                 5                  6                  0               0   \n",
       "3                 6                  7                  1               0   \n",
       "4                 3                  4                  0               0   \n",
       "...             ...                ...                ...             ...   \n",
       "15415             4                  4                  0               0   \n",
       "15416             4                  4                  0               0   \n",
       "15417             3                  3                  0               0   \n",
       "15418             0                  4                  0               0   \n",
       "15419             3                  3                  0               0   \n",
       "\n",
       "       AgentType  NumberOfSuppliments  AddressChange_Claim  NumberOfCars  \\\n",
       "0              0                    3                    0             2   \n",
       "1              0                    3                    3             0   \n",
       "2              0                    3                    3             0   \n",
       "3              0                    2                    3             0   \n",
       "4              0                    3                    3             0   \n",
       "...          ...                  ...                  ...           ...   \n",
       "15415          0                    3                    3             0   \n",
       "15416          0                    2                    3             2   \n",
       "15417          0                    0                    3             0   \n",
       "15418          0                    2                    3             0   \n",
       "15419          0                    0                    3             0   \n",
       "\n",
       "       BasePolicy  \n",
       "0               2  \n",
       "1               1  \n",
       "2               1  \n",
       "3               2  \n",
       "4               1  \n",
       "...           ...  \n",
       "15415           1  \n",
       "15416           2  \n",
       "15417           1  \n",
       "15418           0  \n",
       "15419           1  \n",
       "\n",
       "[15420 rows x 27 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92263157-3689-4a73-bff0-0b1a1d2d08d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.2749 - accuracy: 0.9238\n",
      "Epoch 2/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.2043 - accuracy: 0.9411\n",
      "Epoch 3/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1950 - accuracy: 0.9411\n",
      "Epoch 4/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1899 - accuracy: 0.9411\n",
      "Epoch 5/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1869 - accuracy: 0.9411\n",
      "Epoch 6/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.9411\n",
      "Epoch 7/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1833 - accuracy: 0.9411\n",
      "Epoch 8/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1823 - accuracy: 0.9411\n",
      "Epoch 9/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1812 - accuracy: 0.9411\n",
      "Epoch 10/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.9411\n",
      "Epoch 11/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.9412\n",
      "Epoch 12/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.9413\n",
      "Epoch 13/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1787 - accuracy: 0.9415\n",
      "Epoch 14/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.9415\n",
      "Epoch 15/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1777 - accuracy: 0.9416\n",
      "Epoch 16/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1773 - accuracy: 0.9416\n",
      "Epoch 17/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1768 - accuracy: 0.9418\n",
      "Epoch 18/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.9416\n",
      "Epoch 19/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.9417: 0s - loss: 0.1903 \n",
      "Epoch 20/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1761 - accuracy: 0.9421\n",
      "Epoch 21/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1756 - accuracy: 0.9424\n",
      "Epoch 22/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1753 - accuracy: 0.9423\n",
      "Epoch 23/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.9421\n",
      "Epoch 24/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1749 - accuracy: 0.9424\n",
      "Epoch 25/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1743 - accuracy: 0.9423\n",
      "Epoch 26/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1743 - accuracy: 0.9423\n",
      "Epoch 27/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1740 - accuracy: 0.9422\n",
      "Epoch 28/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1734 - accuracy: 0.9424\n",
      "Epoch 29/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1730 - accuracy: 0.9424\n",
      "Epoch 30/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1732 - accuracy: 0.9423\n",
      "Epoch 31/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1732 - accuracy: 0.9422\n",
      "Epoch 32/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1728 - accuracy: 0.9426\n",
      "Epoch 33/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1725 - accuracy: 0.9427\n",
      "Epoch 34/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1721 - accuracy: 0.9427\n",
      "Epoch 35/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1719 - accuracy: 0.9425\n",
      "Epoch 36/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1716 - accuracy: 0.9426\n",
      "Epoch 37/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1716 - accuracy: 0.9422\n",
      "Epoch 38/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1713 - accuracy: 0.9429\n",
      "Epoch 39/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1712 - accuracy: 0.9424\n",
      "Epoch 40/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1710 - accuracy: 0.9429\n",
      "Epoch 41/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1706 - accuracy: 0.9425\n",
      "Epoch 42/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1706 - accuracy: 0.9425\n",
      "Epoch 43/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1704 - accuracy: 0.9426\n",
      "Epoch 44/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1703 - accuracy: 0.9428\n",
      "Epoch 45/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1699 - accuracy: 0.9427\n",
      "Epoch 46/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1696 - accuracy: 0.9427\n",
      "Epoch 47/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1695 - accuracy: 0.9427\n",
      "Epoch 48/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1697 - accuracy: 0.9424\n",
      "Epoch 49/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1693 - accuracy: 0.9430\n",
      "Epoch 50/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1693 - accuracy: 0.9424\n",
      "Epoch 51/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1688 - accuracy: 0.9429\n",
      "Epoch 52/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1688 - accuracy: 0.9429\n",
      "Epoch 53/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1684 - accuracy: 0.9429\n",
      "Epoch 54/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1686 - accuracy: 0.9432\n",
      "Epoch 55/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1686 - accuracy: 0.9429\n",
      "Epoch 56/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1679 - accuracy: 0.9428\n",
      "Epoch 57/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1683 - accuracy: 0.9429\n",
      "Epoch 58/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1678 - accuracy: 0.9428\n",
      "Epoch 59/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1683 - accuracy: 0.9429\n",
      "Epoch 60/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1680 - accuracy: 0.9429\n",
      "Epoch 61/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1677 - accuracy: 0.9431\n",
      "Epoch 62/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1674 - accuracy: 0.9432\n",
      "Epoch 63/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1674 - accuracy: 0.9434\n",
      "Epoch 64/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1676 - accuracy: 0.9433\n",
      "Epoch 65/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1676 - accuracy: 0.9428\n",
      "Epoch 66/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1672 - accuracy: 0.9426\n",
      "Epoch 67/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1670 - accuracy: 0.9429\n",
      "Epoch 68/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1669 - accuracy: 0.9437\n",
      "Epoch 69/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1666 - accuracy: 0.9434\n",
      "Epoch 70/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1668 - accuracy: 0.9433\n",
      "Epoch 71/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1668 - accuracy: 0.9431\n",
      "Epoch 72/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1665 - accuracy: 0.9429\n",
      "Epoch 73/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1663 - accuracy: 0.9429\n",
      "Epoch 74/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1663 - accuracy: 0.9433\n",
      "Epoch 75/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1660 - accuracy: 0.9436\n",
      "Epoch 76/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1660 - accuracy: 0.9434\n",
      "Epoch 77/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1660 - accuracy: 0.9431\n",
      "Epoch 78/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1660 - accuracy: 0.9430\n",
      "Epoch 79/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1656 - accuracy: 0.9438\n",
      "Epoch 80/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1657 - accuracy: 0.9432\n",
      "Epoch 81/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1655 - accuracy: 0.9436\n",
      "Epoch 82/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1653 - accuracy: 0.9440\n",
      "Epoch 83/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1652 - accuracy: 0.9437\n",
      "Epoch 84/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1650 - accuracy: 0.9436\n",
      "Epoch 85/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1650 - accuracy: 0.9432\n",
      "Epoch 86/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1650 - accuracy: 0.9433\n",
      "Epoch 87/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1649 - accuracy: 0.9433\n",
      "Epoch 88/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1647 - accuracy: 0.9438\n",
      "Epoch 89/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1647 - accuracy: 0.9435\n",
      "Epoch 90/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1645 - accuracy: 0.9436\n",
      "Epoch 91/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1645 - accuracy: 0.9431\n",
      "Epoch 92/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1646 - accuracy: 0.9437\n",
      "Epoch 93/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1644 - accuracy: 0.9435\n",
      "Epoch 94/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1642 - accuracy: 0.9432\n",
      "Epoch 95/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1640 - accuracy: 0.9432\n",
      "Epoch 96/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1642 - accuracy: 0.9437\n",
      "Epoch 97/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1642 - accuracy: 0.9441\n",
      "Epoch 98/100\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.1642 - accuracy: 0.9438\n",
      "Epoch 99/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1639 - accuracy: 0.9436\n",
      "Epoch 100/100\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.1640 - accuracy: 0.9435\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.9351\n",
      "Loss: 0.1932709962129593, Accuracy: 0.9351491332054138\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "data=pd.read_csv('data.csv')\n",
    "if 'FraudFound_P' in data.columns:\n",
    "    X=data.drop('FraudFound_P',axis=1)\n",
    "    y=data['FraudFound_P']\n",
    "else:\n",
    "    print('FraudFound_P is not in dataset')\n",
    "encoder=LabelEncoder()\n",
    "y=encoder.fit_transform(y)\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "if X_train.isnull().any().any():\n",
    "    X_train=X_train.fillna(X_train.mean())\n",
    "if X_test.isnull().any().any():\n",
    "    X_test=X_test.fillna(X_test.mean())\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "model=Sequential()\n",
    "model.add(Dense(units=8,activation='relu',input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(units=16,activation='relu'))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=100,batch_size=32)\n",
    "loss,accuracy=model.evaluate(X_test,y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520c4f83-0df6-415c-a4c5-79edb2536a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hence these are all the above programs are used in the FeedForward Neural Networks\n"
    "Applications of FNN(FeedForward Neural Networks)\n",
    "\n",
    "1) Data Compression\n",
    "2) Pattern recognition\n",
    "3) Computer Vision\n",
    "4) Sonar Target Recognition\n",
    "5) Speech Recognition\n",
    "6) Handwritten Character Recognition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
