{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ee6a78-c826-4755-8dab-70e070be17bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet\n",
    "\n",
    "It was Invented in 2012.\n",
    "Alexnet uses 5 convolutional layers with activation relu.\n",
    "MaxPooling and Dropout are used for to prevent an Overfitting Problems.\n",
    "The Architecture was designed to run on GPUs and was a big breakthrough for large-scale image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325ec9a7-44ea-4270-892f-5d6db2cdfbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Example of Alexnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c936391-df74-4ec9-a686-f79e33ce15a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 264s 211ms/step - loss: 2.3035 - accuracy: 0.0975 - val_loss: 2.3027 - val_accuracy: 0.1025\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 260s 208ms/step - loss: 2.3028 - accuracy: 0.1008 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 259s 207ms/step - loss: 2.3028 - accuracy: 0.1009 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 260s 208ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3029 - val_accuracy: 0.0952\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 283s 227ms/step - loss: 2.3028 - accuracy: 0.1009 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 273s 218ms/step - loss: 2.3028 - accuracy: 0.0975 - val_loss: 2.3029 - val_accuracy: 0.0977\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 258s 206ms/step - loss: 2.3028 - accuracy: 0.0994 - val_loss: 2.3028 - val_accuracy: 0.0977\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 173s 139ms/step - loss: 2.3028 - accuracy: 0.0974 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 173s 138ms/step - loss: 2.3028 - accuracy: 0.0985 - val_loss: 2.3027 - val_accuracy: 0.0977\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 175s 140ms/step - loss: 2.3028 - accuracy: 0.0970 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 2.3026 - accuracy: 0.1000\n",
      "Loss: 2.302616596221924, Accuracy: 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
    "x_train=x_train.astype('float32')/255\n",
    "x_test=x_test.astype('float32')/255\n",
    "y_train=to_categorical(y_train,10)\n",
    "y_test=to_categorical(y_test,10)\n",
    "model=models.Sequential([layers.Conv2D(96,(11,11),activation='relu',input_shape=(32,32,3),strides=2),\n",
    "                         layers.MaxPooling2D(),\n",
    "                         layers.Conv2D(256,(5,5),activation='relu',padding='same'),\n",
    "                         layers.MaxPooling2D(),\n",
    "                         layers.Conv2D(384,(3,3),activation='relu',padding='same'),\n",
    "                         layers.Conv2D(384,(3,3),activation='relu',padding='same'),\n",
    "                         layers.Conv2D(256,(3,3),activation='relu',padding='same'),\n",
    "                         layers.MaxPooling2D(),\n",
    "                         layers.Flatten(),\n",
    "                         layers.Dense(1024,activation='relu'),\n",
    "                         layers.Dropout(0.3),\n",
    "                         layers.Dense(1024,activation='relu'),\n",
    "                         layers.Dropout(0.3),\n",
    "                         layers.Dense(10,activation='softmax')])\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=10,batch_size=32,validation_split=0.2)\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4788429d-8d86-49b4-a6b2-4b588ffb5d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 286s 381ms/step - loss: 0.3048 - accuracy: 0.9055 - val_loss: 0.0979 - val_accuracy: 0.9758\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 298s 397ms/step - loss: 0.1033 - accuracy: 0.9774 - val_loss: 0.0941 - val_accuracy: 0.9778\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 307s 410ms/step - loss: 0.0911 - accuracy: 0.9807 - val_loss: 0.0863 - val_accuracy: 0.9833\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 305s 407ms/step - loss: 0.0588 - accuracy: 0.9867 - val_loss: 0.0724 - val_accuracy: 0.9863\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 303s 405ms/step - loss: 0.0591 - accuracy: 0.9874 - val_loss: 0.0872 - val_accuracy: 0.9844\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 300s 401ms/step - loss: 0.0587 - accuracy: 0.9877 - val_loss: 0.0740 - val_accuracy: 0.9861\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 302s 403ms/step - loss: 0.0552 - accuracy: 0.9883 - val_loss: 0.1038 - val_accuracy: 0.9812\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 302s 403ms/step - loss: 0.0446 - accuracy: 0.9902 - val_loss: 0.0687 - val_accuracy: 0.9875\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 301s 401ms/step - loss: 0.0397 - accuracy: 0.9916 - val_loss: 0.0781 - val_accuracy: 0.9836\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 301s 402ms/step - loss: 0.0419 - accuracy: 0.9920 - val_loss: 0.0609 - val_accuracy: 0.9886\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.0604 - accuracy: 0.9884\n",
      "Loss: 0.06042715534567833,Accuracy: 0.9883999824523926\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "x_train=tf.image.grayscale_to_rgb(tf.image.resize(x_train[...,tf.newaxis],(32,32))).numpy()\n",
    "x_test=tf.image.grayscale_to_rgb(tf.image.resize(x_test[...,tf.newaxis],(32,32))).numpy()\n",
    "x_train=x_train.astype('float32')/255\n",
    "x_test=x_test.astype('float32')/255\n",
    "y_train=to_categorical(y_train,10)\n",
    "y_test=to_categorical(y_test,10)\n",
    "model=models.Sequential([layers.Conv2D(96,(11,11),activation='relu',input_shape=(32,32,3),strides=2),\n",
    "                         layers.MaxPooling2D(),\n",
    "                         layers.Conv2D(256,(5,5),activation='relu',padding='same'),\n",
    "                         layers.MaxPooling2D(),\n",
    "                         layers.Conv2D(384,(3,3),activation='relu',padding='same'),\n",
    "                         layers.Conv2D(384,(3,3),activation='relu',padding='same'),\n",
    "                         layers.Conv2D(256,(3,3),activation='relu',padding='same'),\n",
    "                         layers.MaxPooling2D(),\n",
    "                         layers.Flatten(),\n",
    "                         layers.Dense(4096,activation='relu'),\n",
    "                         layers.Dropout(0.5),\n",
    "                         layers.Dense(4096,activation='relu'),\n",
    "                         layers.Dropout(0.5),\n",
    "                         layers.Dense(10,activation='softmax')])\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=10,batch_size=64,validation_split=0.2)\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(f'Loss: {loss},Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653820c-18b8-49ab-9ac6-0cc95c8d69bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hence these are the example codes for the Alexnet. above strides is used for the Image Pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965a7727-8bea-4421-ba31-afa3af13ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGGNet\n",
    "\n",
    "It was invented in 2014.\n",
    "VGGNet uses 3x3 filters(kernels), but it stacks many convolutional layers(16 or 19 layers).\n",
    "it is known for simpicity and effectiveness, althrough it is conolutionally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d5067-ae16-4602-9f48-ebdf45880c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lets Go with Example codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "087a7452-05f0-4ec7-b590-d1991c4d31f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "625/625 [==============================] - 617s 987ms/step - loss: 2.3034 - accuracy: 0.1001 - val_loss: 2.3029 - val_accuracy: 0.0952\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 649s 1s/step - loss: 2.3029 - accuracy: 0.0985 - val_loss: 2.3029 - val_accuracy: 0.0997\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 2.3027 - accuracy: 0.1000\n",
      "Loss: 2.3026816844940186, Accuracy: 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
    "x_train=x_train.astype('float32')/255\n",
    "x_test=x_test.astype('float32')/255\n",
    "y_train=to_categorical(y_train,10)\n",
    "y_test=to_categorical(y_test,10)\n",
    "model=models.Sequential([layers.Conv2D(64,(3,3),activation='relu',input_shape=(32,32,3),strides=1),\n",
    "                          layers.Conv2D(64,(3,3),activation='relu',padding='same'),\n",
    "                          layers.MaxPooling2D(),\n",
    "                          layers.Conv2D(128,(3,3),activation='relu',padding='same'),\n",
    "                          layers.Conv2D(128,(3,3),activation='relu',padding='same'),\n",
    "                          layers.MaxPooling2D(),\n",
    "                          layers.Conv2D(256,(3,3),activation='relu',padding='same'),\n",
    "                          layers.Conv2D(256,(3,3),activation='relu',padding='same'),\n",
    "                          layers.Conv2D(256,(3,3),activation='relu',padding='same'),\n",
    "                          layers.MaxPooling2D(),\n",
    "                          layers.Conv2D(512,(3,3),activation='relu',padding='same'),\n",
    "                          layers.Conv2D(512,(3,3),activation='relu',padding='same'),\n",
    "                          layers.MaxPooling2D(),\n",
    "                          layers.Flatten(),\n",
    "                          layers.Dense(4096,activation='relu'),\n",
    "                          layers.Dropout(0.5),\n",
    "                          layers.Dense(4096,activation='relu'),\n",
    "                          layers.Dropout(0.5),\n",
    "                          layers.Dense(10,activation='softmax')])\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=2,batch_size=64,validation_split=0.2)\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3be7c717-7f8a-46c7-ab6d-e948a59481b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "750/750 [==============================] - 973s 1s/step - loss: 2.3028 - accuracy: 0.1126 - val_loss: 2.3021 - val_accuracy: 0.1060\n",
      "Epoch 2/2\n",
      "750/750 [==============================] - 986s 1s/step - loss: 2.3014 - accuracy: 0.1139 - val_loss: 2.3023 - val_accuracy: 0.1060\n",
      "313/313 [==============================] - 35s 111ms/step - loss: 2.3011 - accuracy: 0.1135\n",
      "Loss: 2.3011462688446045, Accuracy: 0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models \n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "x_train=tf.image.grayscale_to_rgb(tf.image.resize(x_train[...,tf.newaxis],(32,32))).numpy()\n",
    "x_test=tf.image.grayscale_to_rgb(tf.image.resize(x_test[...,tf.newaxis],(32,32))).numpy()\n",
    "x_train=x_train.astype('float32')/255\n",
    "x_test=x_test.astype('float32')/255\n",
    "y_train=to_categorical(y_train,10)\n",
    "y_test=to_categorical(y_test,10)\n",
    "model=models.Sequential([layers.Conv2D(64,(3,3),activation='relu',input_shape=(32,32,3),strides=1),\n",
    "                         layers.Conv2D(64,(3,3),activation='relu',padding='same'),\n",
    "                         layers.MaxPooling2D(),\n",
    "                         layers.Conv2D(128,(3,3),activation='relu',padding='same'),\n",
    "                         layers.Conv2D(128,(3,3),activation='relu',padding='same'),\n",
    "                         layers.MaxPooling2D(),\n",
    "                         layers.Conv2D(256,(3,3),activation='relu',padding='same'),\n",
    "                         layers.Conv2D(256,(3,3),activation='relu',padding='same'),\n",
    "                         layers.Conv2D(256,(3,3),activation='relu',padding='same'),\n",
    "                         layers.MaxPooling2D(),\n",
    "                         layers.Conv2D(512,(3,3),activation='relu',padding='same'),\n",
    "                         layers.Conv2D(512,(3,3),activation='relu',padding='same'),\n",
    "                         layers.MaxPooling2D(),\n",
    "                         layers.Flatten(),\n",
    "                         layers.Dense(4096,activation='relu'),\n",
    "                         layers.Dropout(0.5),\n",
    "                         layers.Dense(4096,activation='relu'),\n",
    "                         layers.Dropout(0.5),\n",
    "                         layers.Dense(10,activation='softmax')])\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=2,batch_size=64,validation_split=0.2)\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94219945-9f87-4b92-b9c7-31e45d540842",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hence These are the examples for the VGGNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89839d27-49bb-48c1-a7f8-a107cafdbdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleNet(Inception)\n",
    "\n",
    "It was also invented in 2014.\n",
    "GoogleNet uses the Inception modules, which apply multiple convolutional filters(1x1,3x3,5x5) in\n",
    "parallel and concatenate the results.\n",
    "It helps capture features at different features efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4d73b6-c058-4be7-bb76-c568ec99325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lets go with examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f338d57-c021-4519-8e55-8ddf9f7f177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "625/625 [==============================] - 124s 196ms/step - loss: 1.5293 - accuracy: 0.4668 - val_loss: 1.2286 - val_accuracy: 0.5779\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 122s 195ms/step - loss: 1.1248 - accuracy: 0.6072 - val_loss: 1.1085 - val_accuracy: 0.6157\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 1.1056 - accuracy: 0.6156\n",
      "Loss: 1.1055549383163452, Accuracy: 0.6155999898910522\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
    "x_train=x_train.astype('float32')/255\n",
    "x_test=x_test.astype('float32')/255\n",
    "y_train=to_categorical(y_train,10)\n",
    "y_test=to_categorical(y_test,10)\n",
    "def inception_module(x,filters):\n",
    "    f1,f3_r,f3,f5_r,f5,pool=filters\n",
    "    conv1x1=layers.Conv2D(f1,(1,1),padding='same',activation='relu')(x)\n",
    "    conv3x3=layers.Conv2D(f3,(3,3),padding='same',activation='relu')(x)\n",
    "    conv5x5=layers.Conv2D(f5,(5,5),padding='same',activation='relu')(x)\n",
    "    pool=layers.Conv2D(pool,(1,1),padding='same',activation='relu')(x)\n",
    "    x=layers.concatenate([conv1x1,conv3x3,conv5x5,pool],axis=-1)\n",
    "    return x\n",
    "input=layers.Input(shape=(32,32,3))\n",
    "x=inception_module(input,[64,64,128,32,32,32])\n",
    "x=layers.MaxPooling2D()(x)\n",
    "x=layers.Flatten()(x)\n",
    "x=layers.Dense(128,activation='relu')(x)\n",
    "x=layers.Dense(10,activation='softmax')(x)\n",
    "model=models.Model(inputs=input,outputs=x)\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=2,batch_size=64,validation_split=0.2)\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d680967f-ba00-4823-a747-c95d8eabd394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 140s 185ms/step - loss: 0.1402 - accuracy: 0.9565 - val_loss: 0.0703 - val_accuracy: 0.9788\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 143s 190ms/step - loss: 0.0449 - accuracy: 0.9861 - val_loss: 0.0591 - val_accuracy: 0.9826\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 145s 194ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.0568 - val_accuracy: 0.9843\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 124s 165ms/step - loss: 0.0196 - accuracy: 0.9936 - val_loss: 0.0632 - val_accuracy: 0.9844\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 113s 151ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0609 - val_accuracy: 0.9843\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 114s 152ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.0722 - val_accuracy: 0.9824\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 115s 153ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0647 - val_accuracy: 0.9857\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 117s 155ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.0680 - val_accuracy: 0.9851\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 115s 154ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.0704 - val_accuracy: 0.9864\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 117s 156ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0780 - val_accuracy: 0.9847\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.0640 - accuracy: 0.9850\n",
      "Loss: 0.06402499228715897, Accuracy: 0.9850000143051147\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "x_train=tf.image.grayscale_to_rgb(tf.image.resize(x_train[...,tf.newaxis],(32,32))).numpy()\n",
    "x_test=tf.image.grayscale_to_rgb(tf.image.resize(x_test[...,tf.newaxis],(32,32))).numpy()\n",
    "x_train=x_train.astype('float32')/255\n",
    "x_test=x_test.astype('float32')/255\n",
    "y_train=to_categorical(y_train,10)\n",
    "y_test=to_categorical(y_test,10)\n",
    "def inception_module(x,filters):\n",
    "    f1,f3_r,f3,f5_r,f5,pool=filters\n",
    "    conv1x1=layers.Conv2D(f1,(1,1),padding='same',activation='relu')(x)\n",
    "    conv3x3=layers.Conv2D(f3,(3,3),padding='same',activation='relu')(x)\n",
    "    conv5x5=layers.Conv2D(f5,(5,5),padding='same',activation='relu')(x)\n",
    "    pool=layers.Conv2D(pool,(1,1),padding='same',activation='relu')(x)\n",
    "    x=layers.concatenate([conv1x1,conv3x3,conv5x5,pool],axis=-1)\n",
    "    return x\n",
    "input=layers.Input(shape=(32,32,3))\n",
    "x=inception_module(input,[64,64,128,32,32,32])\n",
    "x=layers.MaxPooling2D()(x)\n",
    "x=layers.Flatten()(x)\n",
    "x=layers.Dense(128,activation='relu')(x)\n",
    "x=layers.Dense(10,activation='softmax')(x)\n",
    "model=models.Model(inputs=input,outputs=x)\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=10,batch_size=64,validation_split=0.2)\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e463fc8a-9610-4046-909e-5043a0af2f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hence these are the examples for the GoogleNet(Inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0be769-47ae-4a9f-936a-c126604cfee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet\n",
    "\n",
    "It was invented in 2015.\n",
    "ResNet introduces recidual connections that help to prevent the vanishing Gradient Problem\n",
    "and allow very deep neural networks to be trained effectively.\n",
    "Residual blocks are stacked, and shortcut connections are added to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2428c76-e733-4b9b-a653-97962a818efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lets go through with examples of ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c96ccb37-659e-4671-ac2b-19b209b21ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "625/625 [==============================] - 331s 529ms/step - loss: 1.8387 - accuracy: 0.2989 - val_loss: 1.6558 - val_accuracy: 0.3862\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 365s 584ms/step - loss: 1.5294 - accuracy: 0.4379 - val_loss: 1.4145 - val_accuracy: 0.4863\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 362s 579ms/step - loss: 1.3909 - accuracy: 0.4932 - val_loss: 1.3358 - val_accuracy: 0.5079\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 363s 581ms/step - loss: 1.2795 - accuracy: 0.5394 - val_loss: 1.2325 - val_accuracy: 0.5556\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 366s 585ms/step - loss: 1.1946 - accuracy: 0.5724 - val_loss: 1.1422 - val_accuracy: 0.5922\n",
      "313/313 [==============================] - 24s 75ms/step - loss: 1.1311 - accuracy: 0.5911\n",
      "Loss: 1.131083607673645, Accuracy: 0.5910999774932861\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train,y_train),(x_test,y_test)=cifar10.load_data()\n",
    "x_train=x_train.astype('float32')/255\n",
    "x_test=x_test.astype('float32')/255\n",
    "y_train=to_categorical(y_train,10)\n",
    "y_test=to_categorical(y_test,10)\n",
    "def resnet(x,filters):\n",
    "    shortcut=x\n",
    "    x=layers.Conv2D(filters,(3,3),padding='same',activation='relu')(x)\n",
    "    x=layers.Conv2D(filters,(3,3),padding='same',activation='relu')(x)\n",
    "    x=layers.add([x,shortcut])\n",
    "    x=layers.ReLU()(x)\n",
    "    return x\n",
    "input=layers.Input(shape=(32,32,3))\n",
    "x=layers.Conv2D(64,(3,3),padding='same',activation='relu')(input)\n",
    "x=resnet(x,64)\n",
    "x=resnet(x,64)\n",
    "x=layers.GlobalAveragePooling2D()(x)\n",
    "x=layers.Dense(10,activation='softmax')(x)\n",
    "model=models.Model(inputs=input,outputs=x)\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=5,batch_size=64,validation_split=0.2)\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bd66ffc-ef20-45f3-bf41-eeb7f72e6ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "750/750 [==============================] - 443s 590ms/step - loss: 0.9346 - accuracy: 0.6758 - val_loss: 0.4107 - val_accuracy: 0.8679\n",
      "Epoch 2/5\n",
      "750/750 [==============================] - 438s 583ms/step - loss: 0.2720 - accuracy: 0.9189 - val_loss: 0.1816 - val_accuracy: 0.9490\n",
      "Epoch 3/5\n",
      "750/750 [==============================] - 365s 487ms/step - loss: 0.1717 - accuracy: 0.9500 - val_loss: 0.1456 - val_accuracy: 0.9550\n",
      "Epoch 4/5\n",
      "750/750 [==============================] - 369s 492ms/step - loss: 0.1386 - accuracy: 0.9583 - val_loss: 0.1022 - val_accuracy: 0.9700\n",
      "Epoch 5/5\n",
      "750/750 [==============================] - 396s 527ms/step - loss: 0.1229 - accuracy: 0.9638 - val_loss: 0.1927 - val_accuracy: 0.9448\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.1929 - accuracy: 0.9426\n",
      "Loss: 0.19291909039020538, Accuracy: 0.9426000118255615\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "x_train=tf.image.grayscale_to_rgb(tf.image.resize(x_train[...,tf.newaxis],(32,32))).numpy()\n",
    "x_test=tf.image.grayscale_to_rgb(tf.image.resize(x_test[...,tf.newaxis],(32,32))).numpy()\n",
    "x_train=x_train.astype('float32')/255\n",
    "x_test=x_test.astype('float32')/255\n",
    "y_train=to_categorical(y_train,10)\n",
    "y_test=to_categorical(y_test,10)\n",
    "def resnet(x,filters):\n",
    "    shortcut=x\n",
    "    x=layers.Conv2D(filters,(3,3),padding='same',activation='relu')(x)\n",
    "    x=layers.Conv2D(filters,(3,3),padding='same',activation='relu')(x)\n",
    "    x=layers.add([x,shortcut])\n",
    "    x=layers.ReLU()(x)\n",
    "    return x\n",
    "input=layers.Input(shape=(32,32,3))\n",
    "x=layers.Conv2D(64,(3,3),padding='same',activation='relu')(input)\n",
    "x=resnet(x,64)\n",
    "x=resnet(x,64)\n",
    "x=layers.GlobalAveragePooling2D()(x)\n",
    "x=layers.Dense(10,activation='softmax')(x)\n",
    "model=models.Model(inputs=input,outputs=x)\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=5,batch_size=64,validation_split=0.2)\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7c215f-3b9c-411b-ab82-5b823a4530f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DenseNet\n",
    "\n",
    "It was invented in 2017.\n",
    "DenseNet connects the each layer to each other layer follows feedforward fashion,creating a dense block.\n",
    "This ensures the feature maps from all previous layers are used as input for subsequent layers and improving the \n",
    "flow of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339bf253-cdf7-42fb-b166-dfa345c5cab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
