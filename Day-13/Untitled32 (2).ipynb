{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845bb419-5828-4c41-831f-84d66a9102ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9513047a-5c06-40e3-8cc4-8146e30dad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082da9f1-9aea-4874-a1e7-0fc76af11d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=r\"C:/Users/PythonTeam/Desktop/BALAJI/BALAJI/DL Projects/Federated_Deep_Learning_for_Monkeypox_Disease_Detection_on_GAN-Augmented_Dataset/archive/Monkeypox Skin Image Dataset\"\n",
    "train_dir=os.path.join(directory,'Train')\n",
    "validation_dir=os.path.join(directory,'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db9e52e-b99a-4b62-b29c-826f9a96f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_height,Image_width=224,224\n",
    "Batch_size=32\n",
    "Epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50bcd94a-ac01-4280-86e1-a6832d4a78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagenerator=ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ed9ef8-11bf-4047-a312-4d949922d130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 618 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagenerator.flow_from_directory(\n",
    "    directory,\n",
    "    target_size=(Image_height,Image_width),\n",
    "    batch_size=Batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2427daee-b6fa-4534-97cf-7c3c2c05f64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 152 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator=train_datagenerator.flow_from_directory(\n",
    "    directory,\n",
    "    target_size=(Image_height,Image_width),\n",
    "    batch_size=Batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72dec5f5-7a52-465e-a506-9c67e2872a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model):\n",
    "    model.trainable=True\n",
    "    x=model.output\n",
    "    x=GlobalAveragePooling2D()(x)\n",
    "    x=Dense(1024,activation='relu')(x)\n",
    "    x=Dropout(0.5)(x)\n",
    "    output_layer=Dense(4,activation='softmax')(x)\n",
    "    models=Model(inputs=model.input,outputs=output_layer)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0997da6a-cd19-4546-a2cb-6527313aa192",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode={\n",
    "    'ResNet50V2':ResNet50V2(weights='imagenet',include_top=False,input_shape=(Image_height,Image_width,3))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e5c7f08-8cc7-431f-89ff-d4246af3611b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ResNet50V2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PythonTeam\\anaconda3\\envs\\python39\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 12s/step - accuracy: 0.4675 - loss: 1.2745 - val_accuracy: 0.7039 - val_loss: 0.8108 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 10s/step - accuracy: 0.8167 - loss: 0.5162 - val_accuracy: 0.8158 - val_loss: 0.5754 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 10s/step - accuracy: 0.8821 - loss: 0.3097 - val_accuracy: 0.8158 - val_loss: 0.6196 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 11s/step - accuracy: 0.9427 - loss: 0.2081 - val_accuracy: 0.7697 - val_loss: 0.8289 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 10s/step - accuracy: 0.9468 - loss: 0.1410 - val_accuracy: 0.7368 - val_loss: 0.9138 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 10s/step - accuracy: 0.9497 - loss: 0.1302 - val_accuracy: 0.8026 - val_loss: 0.8039 - learning_rate: 2.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 10s/step - accuracy: 0.9758 - loss: 0.0837 - val_accuracy: 0.7895 - val_loss: 0.6237 - learning_rate: 2.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 10s/step - accuracy: 0.9804 - loss: 0.0767 - val_accuracy: 0.8355 - val_loss: 0.5543 - learning_rate: 2.0000e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 10s/step - accuracy: 0.9729 - loss: 0.0902 - val_accuracy: 0.8421 - val_loss: 0.6385 - learning_rate: 2.0000e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 10s/step - accuracy: 0.9817 - loss: 0.0628 - val_accuracy: 0.8421 - val_loss: 0.6266 - learning_rate: 2.0000e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 10s/step - accuracy: 0.9902 - loss: 0.0450 - val_accuracy: 0.8421 - val_loss: 0.5854 - learning_rate: 2.0000e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 10s/step - accuracy: 0.9790 - loss: 0.0621 - val_accuracy: 0.8487 - val_loss: 0.5891 - learning_rate: 4.0000e-06\n",
      "Epoch 13/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 10s/step - accuracy: 0.9831 - loss: 0.0671 - val_accuracy: 0.8487 - val_loss: 0.5534 - learning_rate: 4.0000e-06\n",
      "Epoch 14/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 11s/step - accuracy: 0.9817 - loss: 0.0780 - val_accuracy: 0.8421 - val_loss: 0.6108 - learning_rate: 4.0000e-06\n",
      "Epoch 15/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 10s/step - accuracy: 0.9791 - loss: 0.0646 - val_accuracy: 0.8618 - val_loss: 0.5778 - learning_rate: 4.0000e-06\n",
      "Epoch 16/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 10s/step - accuracy: 0.9894 - loss: 0.0404 - val_accuracy: 0.8618 - val_loss: 0.5466 - learning_rate: 4.0000e-06\n",
      "Epoch 17/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 9s/step - accuracy: 0.9839 - loss: 0.0640 - val_accuracy: 0.8684 - val_loss: 0.5363 - learning_rate: 4.0000e-06\n",
      "Epoch 18/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 10s/step - accuracy: 0.9934 - loss: 0.0520 - val_accuracy: 0.8553 - val_loss: 0.5129 - learning_rate: 4.0000e-06\n",
      "Epoch 19/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 9s/step - accuracy: 0.9900 - loss: 0.0432 - val_accuracy: 0.8618 - val_loss: 0.5346 - learning_rate: 4.0000e-06\n",
      "Epoch 20/20\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 9s/step - accuracy: 0.9608 - loss: 0.1000 - val_accuracy: 0.8289 - val_loss: 0.5739 - learning_rate: 4.0000e-06\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8641 - loss: 0.6127\n",
      "ResNet50V2 - Validation Loss: 0.5897, Validation Accuracy: 0.8618\n"
     ]
    }
   ],
   "source": [
    "results={}\n",
    "for name,base_model in mode.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model=create_model(base_model)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    Max=model.fit(\n",
    "        train_generator,\n",
    "        epochs=Epochs,\n",
    "        validation_data=validation_generator,\n",
    "        verbose=1,\n",
    "        callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.2,patience=3,min_lr=1e-6)])\n",
    "    loss, accuracy = model.evaluate(validation_generator)\n",
    "    print(f\"{name} - Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}\")\n",
    "    results[name] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f63cc-37cc-4358-85cb-498c332f48a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
